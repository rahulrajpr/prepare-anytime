Notes : 
* collect() method bring `list of the rows` from `executor nodes` to the `driver node` (dataframe --> list of rows)
* read.option('SamplingRatio','true')
* function regexp_expr
* registering the udf in the dataframe function and udf in a sql expression and when the udf is available in the spark catelogue
* spark catelogue listFunctions
* toDF method
* monotonically_increasing_id() function
* passing list of values to methods like .drop("col1","col2","col3") and .dropDuplicate(["col1","col2"]) -- like how to pass the list of values
