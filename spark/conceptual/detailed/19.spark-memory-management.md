# Spark Memory Management & Performance - Interview Guide

## Table of Contents

### 10.1 Memory Architecture & Configuration (24 Questions)
- [10.1.1 Unified Memory Management](#1011-unified-memory-management)
- [10.1.2 Execution vs Storage Memory](#1012-execution-vs-storage-memory)
- [10.1.3 Dynamic Borrowing](#1013-dynamic-borrowing)
- [10.1.4-10.1.24 Configuration & Tuning](#configuration--tuning)

### 10.2 Garbage Collection & JVM Tuning (23 Questions)
- [10.2.1 Role of GC](#1021-role-of-garbage-collection)
- [10.2.2 GC Tuning](#1022-gc-tuning)
- [10.2.3-10.2.23 GC Types & Optimization](#gc-types--optimization)

### 10.3 Data Spilling & Disk I/O (25 Questions)
- [10.3.1 What is Spilling](#1031-what-is-data-spilling)
- [10.3.2 Spilling Causes](#1032-spilling-causes)
- [10.3.3-10.3.25 Prevention & Optimization](#spilling-prevention--optimization)

### 10.4 Caching & Persistence (15 Questions)
- [10.4.1 Caching Location](#1041-caching-location)
- [10.4.2 When to Cache](#1042-when-to-cache)
- [10.4.3-10.4.15 Storage Levels & Trade-offs](#storage-levels--trade-offs)

### 10.5 Serialization & Performance (25 Questions)
- [10.5.1 Importance](#1051-why-serialization-matters)
- [10.5.2-10.5.25 Types & Optimization](#serialization-types--optimization)

---

## 10.1 Memory Architecture & Configuration

### 10.1.1 Explain Spark's Unified Memory Management model

**Answer:** Unified Memory Management (introduced in Spark 1.6) is a dynamic memory allocation system that allows execution and storage memory to share a unified region, eliminating the inefficiencies of fixed, separate memory regions.

**Key Improvements Over Static Memory:**
- **Dynamic Sharing**: Memory borrowed between execution and storage as needed
- **Eviction Policy**: Storage can evict cached data when execution needs memory
- **No Waste**: Eliminates unused memory in fixed regions
- **Automatic**: Minimal manual tuning required

**Memory Architecture:**
```
Total Executor Memory
├── Reserved Memory (300MB fixed) - System operations
├── User Memory (40% default) - UDFs, user data structures
└── Unified Memory (60% default = spark.memory.fraction)
    ├── Storage Memory (50% = spark.memory.storageFraction)
    │   └── Cached RDDs/DataFrames, broadcast variables
    └── Execution Memory (50%)
        └── Shuffle, joins, sorts, aggregations
```

**Dynamic Borrowing:**
- **Execution → Storage**: Can borrow from storage without eviction
- **Storage → Execution**: Can borrow but must evict if execution needs it back
- **Eviction Priority**: Storage memory can be evicted; execution cannot

**Interview Tips:**
- Major improvement in Spark 1.6 replacing Static Memory Management
- Understand the dynamic boundary between storage and execution
- Know that execution has priority over storage

---

### 10.1.2 What is the difference between execution memory and storage memory?

**Answer:** Execution memory is used for computational operations during task execution, while storage memory is used for caching data and broadcast variables that persist across operations.

**Detailed Comparison:**

| Aspect | Execution Memory | Storage Memory |
|--------|-----------------|----------------|
| **Purpose** | Shuffle, joins, sorts, aggregations | Caching, broadcast variables |
| **Operations** | `groupBy`, `join`, `sort` | `cache()`, `persist()`, `broadcast()` |
| **Lifecycle** | Temporary during task execution | Persistent until evicted |
| **Eviction** | Cannot be evicted by storage | Can be evicted by execution |
| **Borrowing** | Can borrow without eviction | Can borrow but may be evicted |
| **Priority** | High - critical for execution | Lower - can be recomputed |

**Interview Tips:**
- Execution memory is for "working" data
- Storage memory is for "persistent" data
- Understanding this distinction is key to memory tuning

---

### 10.1.3 How does unified memory management allow dynamic borrowing?

**Answer:** Dynamic borrowing allows execution and storage to share memory through an eviction mechanism where storage memory can be reclaimed by execution needs, but not vice versa.

**Borrowing Rules:**

**Execution Needs More:**
1. Checks if storage has unused memory
2. If yes, borrows without eviction
3. Returns memory when execution finishes

**Storage Needs More:**
1. Checks if execution has unused memory
2. If yes, borrows from execution
3. BUT: Must evict if execution later needs memory back

**Borrowing Example:**
```
Initial State (60MB unified):
├── Execution: 30MB [========]
└── Storage: 30MB   [========]

Execution Needs 40MB:
├── Execution: 40MB [============] ← Borrowed 10MB
└── Storage: 20MB   [=====]

Storage Needs 40MB Later:
├── Execution: 20MB [=====]
└── Storage: 40MB   [============] ← Borrowed 10MB

Execution Needs Memory Back:
├── Execution: 30MB [========] ← Reclaims memory
└── Storage: 30MB   [========] ← Must evict 10MB
```

**Interview Tips:**
- Execution has priority over storage
- Storage can borrow but may lose it later
- This prevents execution OOM errors

---

## Configuration & Tuning

### 10.1.4 What is spark.memory.fraction and its default value?

**Answer:** `spark.memory.fraction` controls the fraction of heap memory allocated to unified memory (execution + storage), with default value **0.6** (60%).

**Memory Calculation:**
```
executor_memory = 10GB
memory_fraction = 0.6 (60%)

unified_memory = 10GB × 0.6 = 6GB (for execution + storage)
user_memory = 10GB × 0.4 = 4GB (for UDFs, user data)
```

**When to Adjust:**
- **Increase to 0.7**: More computation-heavy jobs
- **Decrease to 0.5**: More UDF-heavy workloads
- **Keep at 0.6**: Default works for most cases

---

### 10.1.5 What does spark.memory.storageFraction control?

**Answer:** `spark.memory.storageFraction` controls the fraction of unified memory initially reserved for storage (caching), with default **0.5** (50%).

**Important:** This is an initial reservation, not a hard limit. The boundary is dynamic.

**Calculation:**
```
unified_memory = 6GB (from memory.fraction)
storageFraction = 0.5 (50%)

storage_reservation = 6GB × 0.5 = 3GB
execution_reservation = 6GB × 0.5 = 3GB
```

**Interview Tips:**
- Initial boundary, not fixed
- Actual usage is dynamic based on workload
- Rarely needs adjustment from default

---

### 10.1.6 How much memory is available for execution vs storage by default?

**Answer:** With 10GB executor memory and default settings, approximately **3GB** is initially allocated to both execution and storage.

**Default Breakdown (10GB executor):**
```
Total: 10GB
├── Reserved: 300MB (3%)
├── User: ~3.88GB (39%)
└── Unified: ~5.82GB (58%)
    ├── Storage: ~2.91GB (29%)
    └── Execution: ~2.91GB (29%)
```

---

### 10.1.7-10.1.8 What is executor memory overhead?

**Answer:** Memory overhead is off-heap memory for JVM internals, native libraries, thread stacks, and OS operations. Default calculation: **max(384MB, 10% of executor memory)**.

**Overhead Includes:**
- JVM metadata and internal structures
- Thread stacks
- Native libraries
- Direct buffer allocations
- OS memory mapping

**When to Increase:**
- Many concurrent tasks
- Memory-intensive native operations
- Seeing "container killed by YARN" errors

---

### 10.1.9 What is the formula for total executor memory?

**Answer:** `Total Memory = Heap Memory + Memory Overhead + Off-heap Memory (optional)`

**Example Calculation:**
```
Heap: 10GB
Overhead: max(384MB, 10GB × 0.1) = 1GB
Off-heap: 0GB (if not enabled)

Total = 10GB + 1GB + 0GB = 11GB
```

---

### 10.1.10 What is spark.executor.memory?

**Answer:** `spark.executor.memory` sets the heap memory size for each executor JVM. Typical range: **4GB-32GB**.

**Setting Methods:**
- Spark submit: `--executor-memory 8g`
- Configuration: `spark.conf.set("spark.executor.memory", "8g")`
- Defaults file: `spark.executor.memory 8g`

**Recommendations:**
- Small workloads: 4GB
- Medium workloads: 8GB
- Large workloads: 16GB
- Memory-intensive: 32GB
- Avoid: >64GB (GC issues)

---

### 10.1.11 What is spark.driver.memory?

**Answer:** `spark.driver.memory` controls driver JVM heap size. Increase when:
- Collecting large results to driver
- Using broadcast joins extensively
- Complex DAG scheduling
- UDF-heavy workloads

**Typical Settings:**
- Default: 1GB
- Small jobs: 2GB
- Medium jobs: 4GB
- Large jobs: 8GB

---

### 10.1.12 What is the difference between on-heap and off-heap memory?

**Answer:** On-heap memory is managed by JVM GC, while off-heap memory is manually managed and not subject to GC pauses.

| Aspect | On-Heap | Off-Heap |
|--------|---------|----------|
| **Management** | JVM Garbage Collection | Manual |
| **GC Impact** | Subject to GC pauses | No GC |
| **Performance** | Faster allocation | Slower allocation |
| **Overhead** | Higher (object headers) | Lower (raw data) |
| **Usage** | Default for most operations | Specialized use |

---

### 10.1.13-10.1.14 Off-heap Memory Configuration

**spark.memory.offHeap.enabled:** Enables off-heap memory usage
**spark.memory.offHeap.size:** Sets off-heap memory amount

**When to Use:**
- High GC time (>10% of task time)
- Large cached datasets causing GC issues
- Need predictable performance

**Trade-offs:**
- Reduces GC pauses
- Adds complexity
- Requires careful sizing

---

### 10.1.15 Benefits of off-heap memory

**Answer:** Off-heap memory provides:
- **Reduced GC Pauses**: Data outside GC scope
- **Larger Memory**: Beyond JVM heap limits
- **Predictable Performance**: No GC stalls
- **Better for Large Datasets**: Handles big data better

**Trade-offs:**
- More complex management
- Manual allocation/deallocation
- Potential memory leaks if not managed properly

---

### 10.1.16-10.1.19 Memory Regions Details

**User Memory (10.1.16):** Reserved for user data structures, UDFs, and non-Spark allocations
- Calculation: `(heap - reserved) × (1 - memory.fraction)`
- Default: ~40% of available heap

**Reserved Memory (10.1.17):** Fixed 300MB for Spark system operations

**Memory Percentage (10.1.19):** Reserved memory percentage varies by executor size:
- 1GB executor: 29.3% reserved (inefficient)
- 4GB executor: 7.3% reserved
- 8GB executor: 3.7% reserved
- 16GB executor: 1.8% reserved

**Interview Tip:** This is why larger executors are more memory-efficient.

---

### 10.1.20 What is the minimum executor memory?

**Answer:** Practical minimum is **1-2GB**, though technically Spark can run with less (not recommended).

**Why Minimum Matters:**
```
512MB executor: 
- Reserved: 300MB (58% wasted!)
- Available: 212MB (minimal for work)

2GB executor:
- Reserved: 300MB (15%)
- Available: 1.7GB (reasonable)
```

**Interview Tip:** Very small executors are inefficient due to fixed 300MB overhead.

---

### 10.1.21 How to calculate optimal executor memory?

**Answer:** Consider data size, operation type, cluster resources, and performance requirements.

**Sizing Guidelines:**

| Data Size | Base Memory | Operation Type Multiplier |
|-----------|-------------|--------------------------|
| <10GB | 4GB | Memory-intensive: 1.5x |
| 10-100GB | 8GB | CPU-intensive: 1.0x |
| 100-500GB | 16GB | Shuffle-heavy: 1.2x |
| >500GB | 32GB | General: 1.0x |

**Best Practices:**
- Start with data size × 2
- Adjust for operation characteristics
- Monitor actual usage
- Cap at reasonable maximum (32-64GB)

---

### 10.1.22 Relationship between executor cores and memory

**Answer:** Cores determine parallelism; memory determines data capacity. Balance based on workload type.

**Balancing Guidelines:**

| Workload Type | Cores | Memory | Memory/Core |
|--------------|-------|---------|-------------|
| CPU-bound | 4 | 8GB | 2GB |
| Memory-bound | 2 | 16GB | 8GB |
| Balanced | 4 | 16GB | 4GB |

**Memory-per-Core Ratio:**
- <1GB: Risk of spilling
- 1-8GB: Good range
- >8GB: Potential GC issues

---

### 10.1.23 Why not allocate too much memory to single executor?

**Answer:** Very large executors cause:

**GC Problems:**
- Long GC pauses (seconds to minutes)
- Unpredictable task execution
- Reduced throughput

**Fault Tolerance Issues:**
- Losing one executor loses significant work
- Longer recovery time
- More recomputation needed

**Resource Issues:**
- Poor cluster utilization
- Memory fragmentation
- Wasted idle memory

**Recommended Limits:**
- Sweet spot: 8-16GB
- Reasonable max: 32GB
- Caution: 64GB
- Avoid: >128GB

---

### 10.1.24 Recommended executor memory size range

**Answer:** Optimal range is **8-16GB** for most workloads, with 8-40GB being acceptable based on requirements.

| Memory Range | Use Case | Pros | Cons |
|--------------|----------|------|------|
| 4-8GB | Small datasets, testing | Fast GC | Limited capacity |
| **8-16GB** | **General purpose** | **Balanced** | **Versatile** |
| 16-32GB | Large datasets | High capacity | Noticeable GC |
| 32-64GB | Memory-intensive | Maximum capacity | Significant GC overhead |
| >64GB | Specialized only | Extreme capacity | Major GC issues |

---

### 10.1.25 Memory management: Spark 1.5 vs 1.6+

**Answer:** Spark 1.5 used Static Memory Management with fixed regions; Spark 1.6+ uses Unified Memory Management with dynamic sharing.

**Static Memory (Pre-1.6):**
- Fixed regions for storage and execution
- No sharing between regions
- Memory wasted when one region underutilized
- Required manual tuning

**Unified Memory (1.6+):**
- Dynamic sharing between regions
- Automatic optimization
- Better memory utilization
- Minimal tuning needed

**Interview Tip:** This was a major architectural improvement in Spark's evolution.

---

## 10.2 Garbage Collection & JVM Tuning

### 10.2.1 Role of garbage collection in Spark

**Answer:** GC manages memory allocation/deallocation for Java objects, directly impacting performance through pause times and throughput.

**GC Impact on Spark:**
- Task execution time (pauses slow processing)
- Memory efficiency (poor GC → memory pressure)
- Job predictability (GC causes variability)
- Throughput (GC time ≠ processing time)

**Monitoring GC:**
- Enable GC logging: `-XX:+PrintGCDetails`
- Check Spark UI: GC time per task
- Monitor frequency and duration
- Watch for Full GC events

---

### 10.2.2 How to tune garbage collection

**Answer:** GC tuning involves selecting collectors, sizing regions, and monitoring behavior to minimize pauses and maximize throughput.

**Tuning Strategy:**

**1. Select Algorithm:**
- Use G1GC: `-XX:+UseG1GC` (recommended)
- Avoid: Serial GC, Parallel GC for most cases
- Consider: ZGC for very large heaps (Spark 3.0+)

**2. Set Pause Goals:**
- Target: `-XX:MaxGCPauseMillis=200`
- Adjust based on latency requirements

**3. Size Regions:**
- Young gen: `-XX:G1NewSizePercent=20-40`
- Initiation: `-XX:InitiatingHeapOccupancyPercent=35`

**4. Monitor and Iterate:**
- Check GC logs
- Adjust based on patterns
- Balance pause time vs throughput

---

### 10.2.3 Young Generation vs Old Generation

**Answer:** Young Generation holds short-lived objects with frequent, fast collection (Minor GC). Old Generation holds long-lived objects with infrequent, slow collection (Major/Full GC).

**Object Lifecycle:**
```
Create → Eden → Minor GC → Survivor → 
Multiple Survivals → Old Gen → Major GC
```

**Impact on Spark:**
- Spark creates many temporary objects
- Most should die young (good)
- Objects reaching Old Gen → problem
- Full GC on Old Gen → long pauses

**Interview Tip:** Monitor object promotion rates to Old Generation.

---

### 10.2.4 What is Full GC and why is it problematic?

**Answer:** Full GC cleans both Young and Old generations, causing long stop-the-world pauses (seconds to minutes) that severely impact performance.

**Problems:**
- **Long Pauses**: All threads stop
- **Cascading Effects**: Slow tasks delay stages
- **Resource Waste**: Idle cluster during GC
- **Unpredictable Performance**: Variable execution times

**Detection:**
- Look for "Full GC" in logs
- Check pause times >1 second
- Monitor frequency
- Watch for increasing trend

---

### 10.2.5 What is Minor GC?

**Answer:** Minor GC cleans only Young Generation, causing short pauses (milliseconds) with minimal performance impact when properly tuned.

**Healthy Pattern:**
- Frequent Minor GCs (many per minute)
- Short pauses (<100ms)
- Low promotion rate to Old Gen
- Consistent task execution

**Unhealthy Pattern:**
- Very frequent Minor GC (overhead)
- Long Minor GC pauses
- High promotion rate
- Increasing Old Gen usage

---

### 10.2.6 What is spark.executor.extraJavaOptions?

**Answer:** Configuration for passing custom JVM options to executor processes, primarily for GC tuning, memory settings, and debugging.

**Common Uses:**
- GC configuration: `-XX:+UseG1GC -XX:MaxGCPauseMillis=200`
- Memory settings: `-Xms4g -Xmx4g`
- GC logging: `-XX:+PrintGCDetails`
- Debugging: `-XX:+HeapDumpOnOutOfMemoryError`

---

### 10.2.7 How to enable GC logging

**Answer:** Enable through JVM options in `spark.executor.extraJavaOptions`:

**Essential Flags:**
- `-XX:+PrintGCDetails`: Detailed GC info
- `-XX:+PrintGCDateStamps`: Timestamps
- `-XX:+PrintGCTimeStamps`: Time since JVM start
- `-Xloggc:/tmp/gc.log`: Log file location

**What to Analyze:**
- Frequency of GC events
- Duration of pauses
- Memory usage patterns
- Promotion rates

---

### 10.2.8 Recommended GC settings for Spark

**Answer:** Use G1GC with tuned pause targets based on executor memory and workload.

**Standard G1GC Configuration:**
```
Base Options:
- -XX:+UseG1GC
- -XX:G1NewSizePercent=20
- -XX:G1MaxNewSizePercent=40
- -XX:InitiatingHeapOccupancyPercent=35

Pause Goals (adjust by memory):
- ≤8GB: -XX:MaxGCPauseMillis=100
- 8-16GB: -XX:MaxGCPauseMillis=200
- >16GB: -XX:MaxGCPauseMillis=300
```

---

### 10.2.9 What is G1GC?

**Answer:** G1GC (Garbage First) is a server-style collector for large heaps providing predictable pause times with high throughput.

**Features:**
- **Region-based**: Divides heap into equal regions
- **Predictable**: Meets pause time goals
- **Concurrent**: Most work done concurrently
- **Compacting**: Avoids fragmentation

**Why for Spark:**
- Good balance of throughput and pause time
- Handles large heaps well
- Requires less tuning than alternatives

---

### 10.2.10 Why is G1GC recommended over traditional GC?

**Answer:** G1GC provides predictable pause times, better large-heap performance, and concurrent collection compared to Serial, Parallel, and CMS collectors.

**Advantages:**

**vs Serial GC:**
- Parallel, not single-threaded
- Suitable for multi-core systems

**vs Parallel GC:**
- Lower pause times
- Better for interactive workloads

**vs CMS:**
- Includes compaction (no fragmentation)
- Simpler tuning
- Better large-heap performance

---

### 10.2.11 What is CMS GC?

**Answer:** CMS (Concurrent Mark Sweep) is a low-pause collector that performs most work concurrently, now largely superseded by G1GC.

**Characteristics:**
- Concurrent collection
- Low pause times
- No compaction (fragmentation risk)
- Complex tuning

**Why G1GC Preferred:**
- Better predictability
- Automatic compaction
- Simpler configuration

---

### 10.2.12 How to configure G1GC for Spark

**Answer:** Configure through executor Java options with pause goals and region sizing.

**Complete Configuration:**
```
-XX:+UseG1GC
-XX:MaxGCPauseMillis=200
-XX:G1NewSizePercent=20
-XX:G1MaxNewSizePercent=40
-XX:InitiatingHeapOccupancyPercent=35
-XX:ConcGCThreads=4
-XX:G1ReservePercent=15
```

**Adjustments for Large Heaps (>32GB):**
- Increase region size: `-XX:G1HeapRegionSize=32m`
- Higher pause tolerance: `-XX:MaxGCPauseMillis=300`

---

### 10.2.13-10.2.15 Key G1GC Parameters

**-XX:+UseG1GC (10.2.13):** Enables G1 Garbage Collector

**-XX:MaxGCPauseMillis (10.2.14):** Target maximum pause time
- Low latency: 100ms
- Balanced: 200ms
- Throughput: 300ms
- Large heaps: 500ms

**-XX:InitiatingHeapOccupancyPercent (10.2.15):** Heap usage % to start concurrent GC
- Default: 45%
- Spark recommendation: 35-40%
- Lower = earlier GC, more frequent
- Higher = later GC, less frequent

---

### 10.2.16 Relationship between GC pauses and task execution

**Answer:** GC pauses directly stop task threads, increasing task duration and potentially creating stragglers that delay stage completion.

**Impact Timeline:**
```
Task: Start → Process → GC Pause (200ms) → Process → End
       ↑                    ↑
    Working           Everything Stops
```

**Straggler Creation:**
- Some tasks with long GC → slow completion
- Other executors wait idle
- Stage delayed by slowest task

---

### 10.2.17 How to identify GC issues in Spark UI

**Answer:** Check task metrics, stage timelines, and executor logs for high GC time or frequent pauses.

**Spark UI Indicators:**

**Task Metrics:**
- High GC time in task details
- Longer duration than peer tasks
- Uneven completion times

**Stage Timeline:**
- Tasks starting together, finishing at different times
- Periodic pause patterns

**Executor Logs:**
- Frequent Full GC events
- Long pause times
- High promotion rates

---

### 10.2.18 What percentage of GC time is concerning?

**Answer:** GC time >10% of task time is critical; >5% warrants monitoring.

**GC Time Thresholds:**
- <5%: Normal, reasonable overhead
- 5-10%: Warning, monitor and consider tuning
- >10%: Critical, significant performance impact

**Analysis:**
```
Task duration: 120s
GC time: 15s
GC percentage: 12.5%
Status: CRITICAL - needs tuning
```

---

### 10.2.19 What is GC overhead?

**Answer:** GC overhead is time spent on garbage collection instead of application work, directly reducing throughput.

**Throughput Impact:**
```
Processing time: 90s
GC time: 10s
Total time: 100s

Effective throughput = (90/100) × theoretical
                     = 90% of potential throughput
```

---

### 10.2.20 How does serialization reduce GC pressure?

**Answer:** Serialization reduces GC by storing data in compact binary formats with fewer objects and longer lifetimes.

**Benefits:**
- Fewer objects allocated
- Less frequent Minor GC
- Reduced promotion to Old Gen
- Lower GC overhead overall

**Example:**
```
Without Kryo: Many Java objects → High GC
With Kryo: Compact byte arrays → Low GC
```

---

### 10.2.21 Impact of caching on GC

**Answer:** Caching increases GC activity by keeping objects in memory longer, potentially promoting them to Old Generation.

**Storage Level Impact:**

**MEMORY_ONLY:**
- Stores deserialized objects
- High memory usage
- High GC pressure

**MEMORY_ONLY_SER:**
- Stores serialized data
- Lower memory usage
- Reduced GC pressure

**Interview Tip:** Choose storage level based on GC tolerance.

---

### 10.2.22 How to reduce object creation

**Answer:** Use primitive types, reuse objects, efficient data structures, and minimize UDFs.

**Techniques:**
- Use built-in functions (not UDFs)
- Prefer primitives over objects
- Reuse objects in loops
- Use efficient collections
- Avoid unnecessary transformations

---

### 10.2.23 What is object pooling?

**Answer:** Object pooling reuses existing objects instead of creating new ones, reducing GC pressure but adding complexity.

**When to Consider:**
- High-frequency UDFs creating many objects
- Custom aggregations with intermediate objects
- Streaming with low-latency requirements

**Trade-off:**
- Reduces GC pressure
- Adds significant complexity
- Rarely needed in practice

**Interview Tip:** Advanced technique; explore other options first.

---

## 10.3 Data Spilling & Disk I/O

### 10.3.1 What is data spilling?

**Answer:** Spilling occurs when Spark writes excess data to disk when memory is insufficient, preventing OOM but significantly impacting performance.

**Common Causes:**
- Insufficient executor memory
- Large aggregations
- Shuffle operations
- Data skew

**Performance Impact:**
```
Memory operation: 60s
With spilling: 300s (5x slower)
Disk I/O is the bottleneck
```

---

### 10.3.2 When and why does spilling occur?

**Answer:** Spilling occurs during memory-intensive operations when executor memory is exhausted.

**Common Triggers:**
- Insufficient executor memory
- Too few partitions (large partition size)
- Data skew (some partitions too large)
- Memory-intensive operations (collect_list, cube)

**Prevention:**
- Increase executor memory
- Increase partition count
- Use efficient serialization
- Handle data skew

---

### 10.3.3 Performance implications of spilling

**Answer:** Spilling causes massive performance degradation due to disk I/O being 50-100x slower than memory.

**Impact Analysis:**
```
Memory speed: 50-100 GB/s
SSD speed: 0.5-5 GB/s
HDD speed: 0.1-0.2 GB/s

Impact: 10-100x slower with spilling
```

**Additional Costs:**
- CPU waits for I/O (idle time)
- Lower overall utilization
- Extended job duration

---

### 10.3.4 Shuffle spill vs storage spill

**Answer:** Shuffle spill occurs during shuffle operations; storage spill occurs during caching.

| Aspect | Shuffle Spill | Storage Spill |
|--------|--------------|---------------|
| **Operation** | Shuffle writes/reads | Caching |
| **Trigger** | Execution memory full | Storage memory full |
| **Data Type** | Intermediate shuffle | Cached DataFrames |
| **Impact** | Slows shuffle stages | Slows cache access |

---

### 10.3.5 What triggers shuffle spill?

**Answer:** Shuffle spill triggers when execution memory is exhausted during sorting, aggregating, or joining.

**Triggers:**
- Memory threshold reached (default 5MB initial)
- Single partition > available memory
- Data skew causing large partitions

**Configuration:**
- `spark.shuffle.spill.initialMemoryThreshold`: 5MB default
- `spark.shuffle.spill.numElementsForceSpillThreshold`: 1M elements

---

### 10.3.6 What triggers storage spill?

**Answer:** Storage spill triggers when cached data exceeds available storage memory.

**Triggers:**
- Storage memory exhausted
- MEMORY_AND_DISK storage level used
- LRU eviction when new data needs caching

**Control:**
```
StorageLevel.MEMORY_ONLY → No spilling (OOM if full)
StorageLevel.MEMORY_AND_DISK → Spill to disk
StorageLevel.MEMORY_ONLY_SER → Less memory, less spilling
```

---

### 10.3.7 How to identify spilling in Spark UI

**Answer:** Check task metrics for "Spill (Memory)" and "Spill (Disk)" values, storage tab for disk usage, and stage details for uneven task times.

**Key Indicators:**

**Task Metrics:**
- Spill (Memory) > 0
- Spill (Disk) > 0
- High shuffle write/read times

**Stage Details:**
- Uneven task completion times
- Some tasks much slower

**Storage Tab:**
- Disk usage for cached data
- Memory vs Disk ratio

---

### 10.3.8 What do spill metrics indicate?

**Answer:** "Spill (Memory)" shows data written to disk; "Spill (Disk)" shows data read back from disk.

**Interpretation:**
- **Spill (Memory)**: Amount written FROM memory TO disk
- **Spill (Disk)**: Amount read FROM disk spills

**Severity Levels:**
- <5% of total data: Minimal spilling, acceptable
- 5-20%: Moderate spilling, monitor
- 20-50%: High spilling, performance degraded
- >50%: Critical spilling, major impact

---

### 10.3.9 Memory fraction vs executor memory for spilling

**Answer:** `spark.executor.memory` sets total heap; `spark.memory.fraction` controls percentage for Spark operations. Both affect spilling.

**Relationship:**
```
executor_memory = 10GB
memory_fraction = 0.6 (60%)

unified_memory = 10GB × 0.6 = 6GB
↓
Spilling occurs when operation needs > 6GB
```

**Tuning for Prevention:**
- Increase executor memory for larger datasets
- Increase memory fraction for computation-heavy workloads
- Balance with cluster resources

---

### 10.3.10 How does increasing executor memory reduce spilling?

**Answer:** More executor memory provides more space for data processing, reducing need to spill to disk.

**Impact:**
```
4GB data with 4GB executor:
- Threshold: 4GB × 0.6 = 2.4GB
- Would spill: 4GB > 2.4GB ✗

4GB data with 8GB executor:
- Threshold: 8GB × 0.6 = 4.8GB
- No spilling: 4GB < 4.8GB ✓
```

---

### 10.3.11 How does increasing partitions affect spilling?

**Answer:** More partitions create smaller partitions that are less likely to exceed memory limits and cause spilling.

**Partition Size Impact:**
```
10GB data ÷ 50 partitions = 200MB per partition
10GB data ÷ 200 partitions = 50MB per partition

With 4GB executor (2.4GB execution memory):
- 200MB partitions: Fits easily ✓
- 2GB partitions: Would spill ✗
```

**Optimal Calculation:**
```
Target partition size: 100-200MB
Optimal partitions = total_data_gb / 0.1
```

---

### 10.3.12 Trade-off between partitions and spilling

**Answer:** Balance between many small partitions (less spilling, more overhead) vs few large partitions (less overhead, more spilling).

| Few Partitions | Many Partitions |
|----------------|-----------------|
| ✅ Less overhead | ✅ Less spilling |
| ✅ Faster startup | ✅ Better balance |
| ❌ Spilling risk | ❌ More overhead |
| ❌ Stragglers | ❌ Task startup time |

**Optimal Balance:**
- Consider memory per core
- Target 100-200MB partitions
- Monitor both spilling and overhead

---

### 10.3.13 What is spark.shuffle.spill.compress?

**Answer:** Controls whether spilled shuffle data is compressed. Default: **true** (enabled and recommended).

**Trade-off:**
- **Enabled**: Reduces disk I/O, uses CPU
- **Disabled**: Lower CPU, more disk I/O

**When to Disable:**
- CPU is proven bottleneck
- Fast disk with spare capacity

**Interview Tip:** Keep enabled for most workloads.

---

### 10.3.14 What is spark.shuffle.spill.batchSize?

**Answer:** Controls how many objects are serialized together when spilling. Default: **10,000**.

**Impact:**
- **Larger**: Fewer files, better compression, more memory during serialization
- **Smaller**: Less memory, more files, worse compression

**Tuning:**
- Large executors (16GB+): 20,000-50,000
- Small executors (≤4GB): 5,000-10,000
- Default (10,000) works well for most cases

---

### 10.3.15 How does serialization format affect spilling?

**Answer:** Efficient serialization (Kryo) reduces memory usage and spilled data size, decreasing spilling frequency and I/O overhead.

**Comparison:**
```
Java Serialization:
- Large serialized size
- More memory usage → more spilling

Kryo Serialization:
- 2-10x smaller size
- Less memory usage → less spilling
```

**Impact:**
```
10GB data with Java: May spill 8GB
10GB data with Kryo: May fit in memory (3GB serialized)
```

---

### 10.3.16 Does Kryo reduce spilling vs Java serialization?

**Answer:** Yes, Kryo significantly reduces spilling by creating smaller serialized objects that use less memory.

**Mechanism:**
```
Without Kryo:
10GB objects → 8GB serialized → Spills 2GB

With Kryo:
10GB objects → 3GB serialized → No spilling!
```

---

### 10.3.17-10.3.18 Impact of spilling on I/O

**Network I/O (10.3.17):**
- Spilled data stays local (no network transfer)
- But slow tasks affect dependent stages
- Indirect impact on network operations

**Disk I/O (10.3.18):**
- Direct and massive impact
- Write to disk + Read from disk
- 50-100x slower than memory
- Becomes primary bottleneck

---

### 10.3.19-10.3.20 Local Disk Configuration

**spark.local.dir (10.3.19):** Specifies directories for temporary files and spilling

**Why Fast Disks Matter (10.3.20):**
```
Performance comparison for 10GB spill:
- HDD: 100 seconds (0.1 GB/s)
- SSD: 5 seconds (2.0 GB/s)
- NVMe: 2 seconds (5.0 GB/s)

20-50x faster with SSDs!
```

**Best Practices:**
- Use multiple SSDs for parallel I/O
- Configure: `/ssd1/spark,/ssd2/spark,/ssd3/spark`
- Prefer NVMe if available
- Avoid network-attached storage

---

### 10.3.21 How does disk speed affect spilling?

**Answer:** Disk speed directly determines spill/read performance, making it critical for spilling scenarios.

**Speed Impact:**
```
5GB spill data:
- HDD (0.1 GB/s): 100s
- SATA SSD (0.5 GB/s): 20s
- NVMe SSD (2.0 GB/s): 5s

20x faster with SSD vs HDD
```

---

### 10.3.22 What happens if spill directories run out of space?

**Answer:** Tasks fail with disk space errors, causing job failures and potential data loss.

**Prevention:**
- Monitor disk usage
- Set up alerts
- Use multiple directories on different disks
- Clean up old Spark applications
- Ensure sufficient disk space

---

### 10.3.23 How to prevent spilling

**Answer:** Increase memory, optimize partitions, use efficient serialization, and choose appropriate algorithms.

**Prevention Checklist:**
1. **Increase Memory**: `spark.executor.memory`
2. **Optimize Partitions**: `spark.sql.shuffle.partitions`
3. **Enable Kryo**: `spark.serializer = KryoSerializer`
4. **Efficient Caching**: `MEMORY_ONLY_SER`
5. **Algorithm Selection**: Use `reduceByKey` not `groupByKey`

---

### 10.3.24 What operations cause spilling?

**Answer:** Memory-intensive operations: large aggregations, sorting, joins, window functions, distinct operations.

**High-Risk Operations:**
- `collect_list()`: Collects large lists
- `sort()`: Requires sorted data in memory
- Large joins: Shuffle operations
- Window functions: Large partitions
- `distinct()`: Tracks all unique values

**Risk Assessment:**
- GroupBy with collect: 2.0x risk factor
- Window functions: 1.8x risk factor
- Sorts: 1.5x risk factor
- Joins: 1.2x risk factor

---

### 10.3.25 How does caching affect spilling?

**Answer:** Caching can both cause (when cache > memory) and prevent (by avoiding recomputation) spilling.

**Causing Spilling:**
```
Large cached dataset → Exceeds storage memory → Spills
```

**Preventing Spilling:**
```
Cache expensive result → Avoid recomputation →
Less memory pressure → Less spilling
```

**Smart Strategy:**
- Cache if multiple uses and fits in memory
- Use `MEMORY_ONLY_SER` for large datasets
- Use `MEMORY_AND_DISK` for safety
- Monitor cache usage

---

## 10.4 Caching & Persistence Strategies

### 10.4.1 Does caching happen on workers or executors?

**Answer:** Caching happens on **executors**, which run on worker nodes. Each executor caches its own partitions locally.

**Architecture:**
```
Cluster
├── Driver (coordinates)
└── Worker Nodes
    └── Executors (cache data in memory/disk)
        ├── Memory (cached partitions)
        └── Disk (spilled cached data)
```

**Interview Tip:** Data stays distributed; driver only manages metadata.

---

### 10.4.2 When should you cache DataFrames?

**Answer:** Cache when data will be used multiple times, especially after expensive transformations. Avoid caching for single use.

**Good Scenarios:**
- Multiple uses of expensive transformations
- Iterative algorithms (ML)
- Interactive exploration
- Multiple downstream operations

**Bad Scenarios:**
- Single use only
- Very large datasets that don't fit
- Immediately used and discarded

---

### 10.4.3 What storage levels are available?

**Answer:** Spark provides multiple storage levels balancing memory, disk, serialization, and replication.

**Available Levels:**
- `MEMORY_ONLY`: Deserialized in memory
- `MEMORY_AND_DISK`: Memory, spill to disk
- `MEMORY_ONLY_SER`: Serialized in memory
- `MEMORY_AND_DISK_SER`: Serialized, spill to disk
- `DISK_ONLY`: Only disk
- `OFF_HEAP`: Off-heap memory
- All with `_2` suffix for replication

---

### 10.4.4 What is MEMORY_ONLY?

**Answer:** Stores deserialized Java objects in memory, providing fastest access but highest memory usage. No spilling - evicts if memory full.

**Characteristics:**
- Fastest read access
- Highest memory usage
- No spilling capability
- Default for `cache()`

**When to Use:**
- Data fits comfortably in memory
- Fast access critical
- Small to medium datasets

---

### 10.4.5 What is MEMORY_AND_DISK?

**Answer:** Stores data in memory but spills to disk when memory full, providing balance between performance and capacity.

**Characteristics:**
- Memory first, disk as backup
- Safe for production
- Handles variable data sizes
- Good default choice

---

### 10.4.6 What is MEMORY_ONLY_SER?

**Answer:** Stores serialized byte arrays in memory, using 2-10x less memory than MEMORY_ONLY but requiring deserialization on access.

**Trade-off:**
- 70-90% memory savings
- CPU overhead for deserialization
- No spilling - evicts if full

**When to Use:**
- Large datasets that must fit in memory
- Memory efficiency more important than access speed

---

### 10.4.7 What is MEMORY_AND_DISK_SER?

**Answer:** Most memory-efficient spillable option - stores serialized data in memory, spills to disk when needed.

**Best For:**
- Large datasets with memory constraints
- Production workloads
- Need both efficiency and safety

---

### 10.4.8 What is DISK_ONLY?

**Answer:** Stores data only on disk, using no memory but with slowest access.

**When to Use:**
- Extreme memory constraints
- Rarely accessed data
- Large archival datasets
- With replication for fault tolerance

**Interview Tip:** Use as last resort due to poor performance.

---

### 10.4.9 What is OFF_HEAP?

**Answer:** Stores data in memory outside JVM heap, avoiding GC but requiring manual management.

**Requirements:**
- Enable: `spark.memory.offHeap.enabled = true`
- Size: `spark.memory.offHeap.size = 4g`

**When to Use:**
- Large cached datasets causing GC issues
- Need to avoid GC pauses
- Have spare off-heap memory

---

### 10.4.10 What storage levels support replication?

**Answer:** All storage levels support replication by adding `_2` suffix (2 replicas) or `_3` suffix (3 replicas).

**Examples:**
- `MEMORY_ONLY_2`
- `MEMORY_AND_DISK_2`
- `DISK_ONLY_2`

**When to Use:**
- Critical data
- Unreliable clusters
- Small enough to afford duplication

**Trade-off:** Doubles storage requirements.

---

### 10.4.11 When to use MEMORY_ONLY vs MEMORY_AND_DISK?

**Answer:** Use MEMORY_ONLY when data fits and speed is critical; use MEMORY_AND_DISK when data might not fit or safety is prioritized.

| Scenario | MEMORY_ONLY | MEMORY_AND_DISK |
|----------|-------------|-----------------|
| Data fits in memory | ✅ Fastest | ⚠️ Safe but slower |
| Data larger than memory | ❌ Fails | ✅ Works |
| Fast access critical | ✅ Best | ⚠️ Slower if spills |
| Production safety | ⚠️ Risky | ✅ Recommended |

---

### 10.4.12 Trade-offs: Deserialized vs Serialized caching

**Answer:** Deserialized offers faster access with more memory usage; serialized offers memory efficiency with CPU overhead.

| Aspect | Deserialized (MEMORY_ONLY) | Serialized (MEMORY_ONLY_SER) |
|--------|---------------------------|------------------------------|
| **Memory** | High (object overhead) | Low (2-10x reduction) |
| **Speed** | Fast (direct access) | Slow (deserialization) |
| **CPU** | Low | High |
| **GC Impact** | High (many objects) | Low (fewer objects) |

---

### 10.4.13 When to use serialized caching?

**Answer:** Use serialized caching for large datasets, high GC pressure, or when memory efficiency trumps access speed.

**Use When:**
- Dataset too large for deserialized caching
- GC time >10% of task time
- Memory-constrained environments
- Batch processing (slight delay acceptable)

---

### 10.4.14 How much memory does serialized caching save?

**Answer:** Serialized caching typically saves **70-90%** of memory, reducing usage by **3-10x**.

**Savings by Data Type:**
- Primitives: 90% savings (10x capacity)
- Strings: 70% savings (3.3x capacity)
- Mixed: 75% savings (4x capacity)
- Complex: 60% savings (2.5x capacity)

**Example:**
```
10GB deserialized → 2.5GB serialized
Savings: 7.5GB (75%)
```

---

### 10.4.15 What is CPU overhead of serialized caching?

**Answer:** Serialized caching adds **20-50% CPU overhead** for serialization/deserialization, but memory savings usually justify this cost.

**Overhead Analysis:**
- Serialization: ~20% overhead (one-time)
- Deserialization: ~30% overhead (per access)
- Total impact depends on access pattern

**When Acceptable:**
- Memory benefit > CPU cost
- CPU not the bottleneck
- Have spare CPU capacity

---

## 10.5 Serialization & Performance

### 10.5.1 Why is serialization important?

**Answer:** Serialization affects data transfer speed, memory usage, and overall performance. Spark frequently serializes for network transfer, spilling, and caching.

**Impact Areas:**
- Network bandwidth usage
- Memory footprint
- Garbage collection overhead
- Shuffle performance
- Caching efficiency

---

### 10.5.2 What serialization types are available?

**Answer:** Java Serialization (default in older versions, inefficient) and Kryo Serialization (faster, more compact, recommended).

**Comparison:**
- Java: Built-in, inefficient, large payloads
- Kryo: Fast, compact, requires configuration

---

### 10.5.3 What is SerDe?

**Answer:** SerDe (Serializer/Deserializer) converts objects to bytes (serialization) and reconstructs objects from bytes (deserialization).

---

### 10.5.4 Performance differences: Java vs Kryo

**Answer:** Kryo is typically **2-10x faster** and produces **2-10x smaller** serialized data compared to Java serialization.

---

### 10.5.5 How much faster is Kryo?

**Answer:** Kryo is generally **2-10x faster** in serialization/deserialization speed and produces **2-10x smaller** data, depending on data types and class registration.

---

### 10.5.6 How to enable Kryo serialization?

**Answer:** Set `spark.serializer` to `org.apache.spark.serializer.KryoSerializer`.

---

### 10.5.7 What is spark.serializer?

**Answer:** Configuration specifying which serialization library Spark uses. Set to `org.apache.spark.serializer.KryoSerializer` for Kryo.

---

### 10.5.8 What is spark.kryo.registrationRequired?

**Answer:** Controls whether Kryo requires explicit class registration. When `true`, unregistered classes cause serialization failure, helping catch issues early.

---

### 10.5.9 What is spark.kryo.classesToRegister?

**Answer:** Comma-separated list of classes to pre-register with Kryo, improving performance by avoiding storing class names with each object.

---

### 10.5.10 Why register classes with Kryo?

**Answer:** Registration improves performance - Kryo uses numeric IDs instead of full class names, reducing serialized size and speeding up serialization.

---

### 10.5.11 What happens without class registration?

**Answer:** Kryo still works but stores full class names with each object, increasing payload size and adding overhead for class lookup.

---

### 10.5.12 Cost of class registration?

**Answer:** Minimal one-time setup overhead during initialization. Performance benefits during execution far outweigh this cost.

---

### 10.5.13 How does serialization affect shuffle?

**Answer:** Serialization directly impacts shuffle performance - efficient serialization reduces network bandwidth usage and decreases shuffle time.

---

### 10.5.14 How does serialization affect caching?

**Answer:** Efficient serialization allows more data to fit in memory cache, reducing spilling and improving cache utilization.

---

### 10.5.15 How does serialization affect network transfer?

**Answer:** Smaller serialized payloads reduce network congestion and decrease transfer times, improving overall job performance.

---

### 10.5.16 What data types benefit most from Kryo?

**Answer:** Primitive types, arrays, collections, and complex objects with deep hierarchies benefit most when properly registered.

---

### 10.5.17 When is Java serialization preferred?

**Answer:** Rarely preferred; might be used for complex object graphs Kryo can't handle or during migration. Kryo should be the goal for production.

---

### 10.5.18 What is broadcast serialization?

**Answer:** Process of serializing broadcast variables before sending to all executors. Efficient serialization reduces broadcast time and memory usage.

---

### 10.5.19 How does serialization affect broadcast joins?

**Answer:** Efficient serialization reduces broadcast table size and transfer time, making broadcast joins faster and more memory-efficient.

---

### 10.5.20 What is task serialization?

**Answer:** Serialization of task objects (closures, functions) to send to executors. Occurs for every task and benefits from efficient serialization.

---

### 10.5.21 What causes "Task not serializable" errors?

**Answer:** Attempting to serialize tasks containing non-serializable objects - typically external variables, database connections, or non-Serializable objects.

---

### 10.5.22 How to fix task serialization issues?

**Answer:** Ensure all closure objects are serializable, use local variables, mark fields transient if not needed, or use broadcast variables for shared data.

---

### 10.5.23 What objects must be serializable?

**Answer:** All objects in task closures, captured variables in lambdas, UDF objects, and data transferred from driver to executors.

---

### 10.5.24 How to make custom classes serializable?

**Answer:** Implement `Serializable` interface for Java serialization or register with Kryo. For Kryo, use no-arg constructor and field serialization.

---

### 10.5.25 Best practices for serialization

**Answer:** Always use Kryo, register custom classes, use primitives when possible, avoid complex closures, use broadcast variables for shared data, test with specific data types.

---

## Interview Preparation Summary

### Most Important Concepts

**Memory Management:**
- ✅ Unified Memory Management (dynamic sharing)
- ✅ Execution vs Storage memory (priorities)
- ✅ Default memory breakdown (60/40 split)
- ✅ Memory tuning parameters

**Garbage Collection:**
- ✅ Use G1GC for most workloads
- ✅ Monitor GC time (<10% threshold)
- ✅ Young vs Old generation
- ✅ Full GC is problematic

**Data Spilling:**
- ✅ Spilling = major performance killer
- ✅ Prevention strategies (memory, partitions, serialization)
- ✅ Use SSDs for spill directories
- ✅ Monitor spill metrics in Spark UI

**Caching:**
- ✅ Storage levels and trade-offs
- ✅ MEMORY_AND_DISK_SER for production
- ✅ Cache selectively (not everything)
- ✅ Monitor cache usage

**Serialization:**
- ✅ Always use Kryo in production
- ✅ Register classes for best performance
- ✅ 2-10x improvements possible
- ✅ Critical for shuffle and caching

### Common Interview Questions

1. **"Explain Unified Memory Management"**
   - Dynamic sharing between execution and storage
   - Execution has priority
   - Introduced in Spark 1.6

2. **"How do you tune GC for Spark?"**
   - Use G1GC
   - Set appropriate pause targets
   - Monitor GC time percentage

3. **"What causes data spilling?"**
   - Insufficient memory
   - Large partitions
   - Memory-intensive operations

4. **"When should you cache DataFrames?"**
   - Multiple uses
   - After expensive transformations
   - Not for single use

5. **"Why use Kryo over Java serialization?"**
   - 2-10x faster
   - 2-10x smaller
   - Reduces memory and network usage

### Quick Reference

**Memory Tuning:**
```
spark.executor.memory: 8-16GB (sweet spot)
spark.memory.fraction: 0.6 (default)
spark.memory.storageFraction: 0.5 (default)
```

**GC Tuning:**
```
-XX:+UseG1GC
-XX:MaxGCPauseMillis=200
-XX:InitiatingHeapOccupancyPercent=35
```

**Serialization:**
```
spark.serializer = org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired = false (initially)
```

**Caching:**
```
Production: MEMORY_AND_DISK_SER
Fast access: MEMORY_ONLY
Memory-efficient: MEMORY_ONLY_SER
```

---

**Total Questions: 112**
- Memory Architecture: 25 questions
- GC & JVM: 23 questions  
- Spilling: 25 questions
- Caching: 15 questions
- Serialization: 25 questions

**End of Document**
