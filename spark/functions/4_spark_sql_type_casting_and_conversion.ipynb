{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe3ynuLL0v/9T3/TFITYZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrajpr/prepare-anytime/blob/main/spark/functions/4_spark_sql_type_casting_and_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Casting Functions\n",
        "https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#conversion-functions"
      ],
      "metadata": {
        "id": "cvlCseU-wlDj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vYUGjdDwefF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('spark-casting').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the cast function\n",
        "\n",
        "sql = '''select cast('109' as int) as castedValue'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xC91q74xEN7",
        "outputId": "6b05e7b1-8f00-42fa-9150-b1240b515b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|castedValue|\n",
            "+-----------+\n",
            "|109        |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''select cast(100 as string) as castedValue''' ## mostly useful without length restriction\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select cast(100 as char(15)) as castedValue''' ## char only supports when the length is specified\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select cast(100 as varchar(10)) as castedValue'''  ## varchar only supports when the length is specified\n",
        "spark.sql(sql).show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N6_yuiAyk-d",
        "outputId": "3a057152-134e-421d-b07c-9660f5346cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|castedValue|\n",
            "+-----------+\n",
            "|100        |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|castedValue|\n",
            "+-----------+\n",
            "|100        |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|castedValue|\n",
            "+-----------+\n",
            "|100        |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supported String Types in Spark SQL\n",
        "\n",
        "| Type | Length Required | Notes / Usage |\n",
        "|------|----------------|---------------|\n",
        "| `STRING` | No | Standard text type, safest choice, works without specifying length |\n",
        "| `CHAR(n)` | Yes | Fixed-length string. Pads/truncates to the specified length `n` |\n",
        "| `VARCHAR(n)` | Yes | Variable-length string, max length = `n`. Most use cases prefer `STRING` |"
      ],
      "metadata": {
        "id": "iLB5d5sv7TQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Specific Casting Functions\n",
        "\n",
        "| Function | Description |\n",
        "|----------|-------------|\n",
        "| `tinyint(expr)` | Casts the value `expr` to the target data type `tinyint` |\n",
        "| `smallint(expr)` | Casts the value `expr` to the target data type `smallint` |\n",
        "|  |  |\n",
        "| `int(expr)` | Casts the value `expr` to the target data type `int` |\n",
        "| `bigint(expr)` | Casts the value `expr` to the target data type `bigint` |\n",
        "|  |  |\n",
        "| `binary(expr)` | Casts the value `expr` to the target data type `binary` |\n",
        "|  |  |\n",
        "| `boolean(expr)` | Casts the value `expr` to the target data type `boolean` |\n",
        "|  |  |\n",
        "| `date(expr)` | Casts the value `expr` to the target data type `date` |\n",
        "|  |  |\n",
        "| `decimal(expr)` | Casts the value `expr` to the target data type `decimal` |\n",
        "| `double(expr)` | Casts the value `expr` to the target data type `double` |\n",
        "| `float(expr)` | Casts the value `expr` to the target data type `float` |\n",
        "|  |  |\n",
        "| `string(expr)` | Casts the value `expr` to the target data type `string` |\n",
        "|  |  |\n",
        "| `timestamp(expr)` | Casts the value `expr` to the target data type `timestamp` |"
      ],
      "metadata": {
        "id": "xr5AVJIg7s1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tinyint\n",
        "\n",
        "# Minimum value: -128\n",
        "# Maximum value: 127\n",
        "\n",
        "sql = '''select tinyint('6') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select tinyint('200') as castedOut''' ## in this case, the conversion will return a NULL, as the lmit exceeded\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhu4jMnu-eim",
        "outputId": "27994e9e-7906-47d0-b1e2-0e4948a79c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|6        |\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|NULL     |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# smallint\n",
        "\n",
        "# Minimum value: -32,768\n",
        "# Maximum value: 32,767\n",
        "\n",
        "sql = '''select smallint('6') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select smallint('35,000') as castedOut''' ## in this case, the conversion will return a NULL, as the lmit exceeded\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgVom_KqAE6q",
        "outputId": "3ee27bd6-b3b1-4c95-a91f-4f07a76c24f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|6        |\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|NULL     |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# int\n",
        "\n",
        "# Minimum value: -2,147,483,648\n",
        "# Maximum value: 2,147,483,647\n",
        "\n",
        "sql = '''select int(10.5) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select int('2,222,000,000') as castedOut''' ## in this case, the conversion will return a NULL, as the lmit exceeded\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EFugu7O-yg-",
        "outputId": "1992dbbf-318c-489c-865e-c91fd5401262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|10       |\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|NULL     |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bigint\n",
        "\n",
        "# Minimum value: -9,223,372,036,854,775,808\n",
        "# Maximum value: 9,223,372,036,854,775,807\n",
        "\n",
        "sql = '''select bigint('9000000000000') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select bigint('9,000,000,000,000,000,000') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTST6CJb_Aq8",
        "outputId": "144c3da9-2124-4cd9-e98d-40d9baa3b4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|castedOut    |\n",
            "+-------------+\n",
            "|9000000000000|\n",
            "+-------------+\n",
            "\n",
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|NULL     |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary\n",
        "\n",
        "sql = '''select binary('rahul') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1J-Dg70BWC6",
        "outputId": "cb9d2619-cb31-410e-9d6a-ca30e652f84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|castedOut       |\n",
            "+----------------+\n",
            "|[72 61 68 75 6C]|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boolean\n",
        "\n",
        "sql = '''select '1' as val,boolean('1') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 1 as val,boolean(1) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select '0' as val,boolean('0') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 0 as val,boolean(0) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select '-1' as val,boolean('-1') as castedOut''' ## string negative value\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select -1 as val,boolean(-1) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select True as val,boolean(True) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 'True' as val,boolean('True') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 'true' as val,boolean('true') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 'T' as val,boolean('T') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 't' as val,boolean('t') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 100 as val,boolean(100) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select 'rahul' as val,boolean('rahul') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select NULL as val,boolean(NULL) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYjwaDJBg2H",
        "outputId": "d301e212-242c-45d1-a1d7-23f5456e25cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|1  |true     |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|1  |true     |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|0  |false    |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|0  |false    |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|-1 |NULL     |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|-1 |true     |\n",
            "+---+---------+\n",
            "\n",
            "+----+---------+\n",
            "|val |castedOut|\n",
            "+----+---------+\n",
            "|true|true     |\n",
            "+----+---------+\n",
            "\n",
            "+----+---------+\n",
            "|val |castedOut|\n",
            "+----+---------+\n",
            "|True|true     |\n",
            "+----+---------+\n",
            "\n",
            "+----+---------+\n",
            "|val |castedOut|\n",
            "+----+---------+\n",
            "|true|true     |\n",
            "+----+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|T  |true     |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|t  |true     |\n",
            "+---+---------+\n",
            "\n",
            "+---+---------+\n",
            "|val|castedOut|\n",
            "+---+---------+\n",
            "|100|true     |\n",
            "+---+---------+\n",
            "\n",
            "+-----+---------+\n",
            "|val  |castedOut|\n",
            "+-----+---------+\n",
            "|rahul|NULL     |\n",
            "+-----+---------+\n",
            "\n",
            "+----+---------+\n",
            "|val |castedOut|\n",
            "+----+---------+\n",
            "|NULL|NULL     |\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date\n",
        "\n",
        "sql = '''select date('2025-10-25') as castedOut'''  ## only supports ISO Date Formatting , best case use to_date() format\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRLUA7dnEK4x",
        "outputId": "8b217367-8923-43ac-a76d-e6d527a609c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|castedOut |\n",
            "+----------+\n",
            "|2025-10-25|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL Date Parsing Notes\n",
        "\n",
        "## Understanding Date Parsing Behavior\n",
        "\n",
        "Spark SQL has two main approaches to parsing dates:\n",
        "1. **Default parsing** with `DATE()` or `CAST AS DATE` - limited format support\n",
        "2. **Custom format parsing** with `TO_DATE(expr, format)` - flexible format support\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Default `DATE()` / `CAST(... AS DATE)` Behavior\n",
        "\n",
        "### Reliably Supported Format\n",
        "\n",
        "| Pattern | Example | Notes |\n",
        "|---------|---------|-------|\n",
        "| `yyyy-MM-dd` | `2025-10-25` | Standard ISO format - **only reliably supported format** |\n",
        "| `yyyy-MM-dd HH:mm:ss` | `2025-10-25 14:30:00` | Time part ignored for `DATE()` |\n",
        "| `yyyy-MM-ddTHH:mm:ss` | `2025-10-25T14:30:00` | ISO 8601 format |\n",
        "| `yyyy-MM-dd HH:mm:ss.SSS` | `2025-10-25 14:30:00.123` | Milliseconds ignored |\n",
        "\n",
        "> **Critical Rule:** Default `DATE()` and `CAST AS DATE` primarily support `yyyy-MM-dd` format. Other formats may return NULL or require `TO_DATE()` with explicit format specification.\n",
        "\n",
        "\n",
        "## 2 Using `TO_DATE(string, format)` for Custom Patterns\n",
        "\n",
        "Use `TO_DATE()` when the date string is not in ISO `yyyy-MM-dd` format or contains month names.\n",
        "\n",
        "| Format String | Example Input | Example Query |\n",
        "|---------------|---------------|---------------|\n",
        "| `yyyyMMdd` | `20251025` | `SELECT TO_DATE('20251025', 'yyyyMMdd');` |\n",
        "| `yyyy-MMM-dd` | `2025-Oct-25` | `SELECT TO_DATE('2025-Oct-25', 'yyyy-MMM-dd');` |\n",
        "| `dd-MM-yyyy` | `25-10-2025` | `SELECT TO_DATE('25-10-2025', 'dd-MM-yyyy');` |\n",
        "| `dd/MM/yyyy` | `25/10/2025` | `SELECT TO_DATE('25/10/2025', 'dd/MM/yyyy');` |\n",
        "| `MMM dd, yyyy` | `Oct 25, 2025` | `SELECT TO_DATE('Oct 25, 2025', 'MMM dd, yyyy');` |\n",
        "| `dd MMM yyyy` | `25 Oct 2025` | `SELECT TO_DATE('25 Oct 2025', 'dd MMM yyyy');` |\n",
        "| `MM/dd/yyyy` | `10/25/2025` | `SELECT TO_DATE('10/25/2025', 'MM/dd/yyyy');` |\n",
        "\n",
        "> **Important:** Pattern letters are case-sensitive. Use lowercase `d` for day-of-month, lowercase `yyyy` for year, and `MM` for month number. Use `MMM` for abbreviated month names.\n",
        "\n",
        "---\n",
        "\n",
        "## 3 Key Notes\n",
        "\n",
        "1. **Default `DATE()` support is limited** - Only `yyyy-MM-dd` ISO format is reliably auto-cast\n",
        "2. **Non-ISO formats require `TO_DATE()`** - Use format string parameter for custom patterns\n",
        "3. **Month names always require `TO_DATE()`** - No month name parsing in default `DATE()`\n",
        "4. **Time parts are ignored** - `DATE()` extracts only the date portion from timestamps\n",
        "5. **Invalid strings return NULL** - Both `DATE()` and `TO_DATE()` return NULL for unparseable strings\n",
        "6. **Pattern syntax follows Java DateTimeFormatter** - Refer to Spark documentation for all pattern letters\n",
        "\n",
        "---\n",
        "\n",
        "## 4.Examples\n",
        "```sql\n",
        "-- ✅ Default DATE() works - ISO format\n",
        "SELECT DATE('2025-10-25') AS result;  -- 2025-10-25\n",
        "SELECT DATE('2025-10-25 14:30:00') AS result;  -- 2025-10-25\n",
        "\n",
        "-- ✅ Custom TO_DATE() works for all formats\n",
        "SELECT TO_DATE('20251025', 'yyyyMMdd') AS result;  -- 2025-10-25\n",
        "SELECT TO_DATE('2025-Oct-25', 'yyyy-MMM-dd') AS result;  -- 2025-10-25\n",
        "SELECT TO_DATE('25-10-2025', 'dd-MM-yyyy') AS result;  -- 2025-10-25\n",
        "SELECT TO_DATE('Oct 25, 2025', 'MMM dd, yyyy') AS result;  -- 2025-10-25\n",
        "SELECT TO_DATE('10/25/2025', 'MM/dd/yyyy') AS result;  -- 2025-10-25\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5 Best Practices\n",
        "\n",
        "1. **Prefer ISO format** (`yyyy-MM-dd`) when possible - no parsing needed\n",
        "2. **Always use `TO_DATE()` with format** for non-ISO strings\n",
        "3. **Test your date patterns** - pattern letters are case-sensitive\n",
        "4. **Handle NULLs gracefully** - invalid dates will return NULL\n",
        "5. **Document date formats** in your data pipelines for maintainability"
      ],
      "metadata": {
        "id": "AX_8Od9yFFRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decimal\n",
        "\n",
        "sql = '''select decimal(123.56) as castedOut''' ## default (10,2) decimal\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "## -- correct usage with a cast function\n",
        "\n",
        "sql = '''select cast(123.56 as decimal(10,3)) castedOut''' ## default (10,2) decimal\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ZxQiV-IOy8",
        "outputId": "fe037064-7de6-4873-c304-c7f1f6940f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|124      |\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|123.560  |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# float\n",
        "\n",
        "sql = '''select float(123.56) as castedOut''' ## default (10,2) decimal\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiMHQ43EIPJu",
        "outputId": "374dfb73-41e7-49e0-da67-270b5c3e806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|123.56   |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# double\n",
        "\n",
        "sql = '''select double(123.56) as castedOut''' ## default (10,2) decimal\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzYerjD-IPmH",
        "outputId": "3c2202d9-7f07-4dfe-e5c1-eedd33bbc0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|123.56   |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quick Comparison\n",
        "\n",
        "| Feature | FLOAT | DOUBLE | DECIMAL |\n",
        "|---------|-------|--------|---------|\n",
        "| **Precision** | 32-bit (~7 digits) | 64-bit (~15-16 digits) | Up to 38 digits |\n",
        "| **Storage** | 4 bytes | 8 bytes | Variable |\n",
        "| **Arithmetic** | Approximate | Approximate | Exact |\n",
        "| **Rounding Errors** | Yes | Yes | No |\n",
        "| **Performance** | Fastest | Fast | Slower |\n",
        "| **Best For** | Scientific calculations, ML | General floating-point | Financial, monetary |\n",
        "\n",
        "#### Key Rules\n",
        "\n",
        "1. **Financial/Money/Currency data → Always use DECIMAL**\n",
        "2. **Scientific/ML data → Use FLOAT or DOUBLE**\n"
      ],
      "metadata": {
        "id": "zkiMf5Q6LLEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# string\n",
        "\n",
        "sql = '''select string(123.56) as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC_n0nVHL-pi",
        "outputId": "c7fdd258-8320-42d1-dc3f-567fbe2a133f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|123.56   |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# timestamp\n",
        "\n",
        "sql = '''select timestamp('2025-10-25 12:12:12') as castedOut'''\n",
        "spark.sql(sql).show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tlMiR6AMN7D",
        "outputId": "9ed0c9be-3712-4836-9ada-4bd8c9d59726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|castedOut          |\n",
            "+-------------------+\n",
            "|2025-10-25 12:12:12|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Type Conversion Functions (to_ Functions) in Spark SQL\n",
        "\n",
        "| Function | Converts From | Converts To | Description |\n",
        "|----------|---------------|-------------|-------------|\n",
        "| `to_char(expr, format)` | Date / Timestamp | String | Converts a date or timestamp to a formatted string |\n",
        "| `to_varchar(expr, format)` | Any | Varchar | Converts any data type to varchar with specified maximum length |\n",
        "|  |  |  |\n",
        "| `to_number(expr,format)` | String / Numeric | Numeric | Converts a string or numeric value to a numeric type |\n",
        "|  |  |  |\n",
        "| `to_date(expr, format)` | String / Timestamp | Date | Converts a string or timestamp to a date using the specified format |\n",
        "| `to_timestamp(expr, format)` | String | Timestamp | Converts a string to a timestamp using the specified format |\n",
        "|  |  |  |\n",
        "| `to_json(expr)` | Struct / Map / Array | String (JSON) | Converts complex data structures to JSON string format |\n",
        "|  |  |  |\n",
        "| `to_binary(expr)` | String | Binary | Converts a string to binary data |"
      ],
      "metadata": {
        "id": "f6IYxrbX-Ti8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to_char\n",
        "\n",
        "sql = '''SELECT to_char(167, '999.99') AS castedOut''' ## requires a formatting pattern\n",
        "spark.sql(sql).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD31bPuC-W5F",
        "outputId": "9f3c317c-8d03-4db6-afe6-a7937057bcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|167.00   |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_varchar(expr, format)\n",
        "\n",
        "sql = '''SELECT to_varchar(12345,'99999.99') AS castedOut''' ## requires a formatting pattern\n",
        "spark.sql(sql).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O08ew1i4Vh0Q",
        "outputId": "4ec9333a-7a8f-45d7-d37a-dacade22b01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|12345.00 |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_number(expr)\n",
        "\n",
        "sql = '''SELECT TO_NUMBER('12345', '99999') AS castedOut''' ## requires a formatting pattern\n",
        "spark.sql(sql).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWBixRU2V6P6",
        "outputId": "eb69993c-2c5e-4835-e0eb-582a2b56fc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|12345    |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_date(expr, format) : returning a date object\n",
        "\n",
        "## the pattern is the pattern of the datestring within the input column, it is NOT the output pattern\n",
        "\n",
        "sql = '''SELECT to_date('25-10-2025', 'dd-MM-yyyy') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_date('10/25/2025', 'MM/dd/yyyy') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_date('Oct 25, 2025', 'MMM dd, yyyy') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_date(timestamp('2025-10-25 12:30:45')) AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GW7wqAfWUPq",
        "outputId": "3fafcd04-5032-4be8-e398-9ccc98990849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|castedOut |\n",
            "+----------+\n",
            "|2025-10-25|\n",
            "+----------+\n",
            "\n",
            "+----------+\n",
            "|castedOut |\n",
            "+----------+\n",
            "|2025-10-25|\n",
            "+----------+\n",
            "\n",
            "+----------+\n",
            "|castedOut |\n",
            "+----------+\n",
            "|2025-10-25|\n",
            "+----------+\n",
            "\n",
            "+----------+\n",
            "|castedOut |\n",
            "+----------+\n",
            "|2025-10-25|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_timestamp(expr, format) : returning a datetime object\n",
        "\n",
        "## the pattern is the pattern of the datestring within the input column, it is NOT the output pattern\n",
        "\n",
        "sql = '''SELECT to_timestamp('2025-10-25 12:30:45', 'yyyy-MM-dd HH:mm:ss') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_timestamp('10/25/2025 14:30:00', 'MM/dd/yyyy HH:mm:ss') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_timestamp('2025-10-25 12:30:45.123', 'yyyy-MM-dd HH:mm:ss.SSS') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)\n",
        "\n",
        "sql = '''SELECT to_timestamp('2025-10-25 12:30:45') AS castedOut'''\n",
        "spark.sql(sql).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lpsvoTSXZdQ",
        "outputId": "7430274b-07ee-4690-fb7c-7ce51aa56133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|castedOut          |\n",
            "+-------------------+\n",
            "|2025-10-25 12:30:45|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|castedOut          |\n",
            "+-------------------+\n",
            "|2025-10-25 14:30:00|\n",
            "+-------------------+\n",
            "\n",
            "+-----------------------+\n",
            "|castedOut              |\n",
            "+-----------------------+\n",
            "|2025-10-25 12:30:45.123|\n",
            "+-----------------------+\n",
            "\n",
            "+-------------------+\n",
            "|castedOut          |\n",
            "+-------------------+\n",
            "|2025-10-25 12:30:45|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_json (from a map)\n",
        "\n",
        "sql = '''\n",
        "with cte as\n",
        "(\n",
        "select map('name','rahul','interest','data engineering') as inp\n",
        ")\n",
        "select\n",
        "  inp,\n",
        "  typeOf(inp) as inpType,\n",
        "  to_json(inp) as out,\n",
        "  typeOf(to_json(inp)) as outType\n",
        "from cte\n",
        "'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9swO0nYNqp",
        "outputId": "d1ef8fa6-cd24-4751-a023-ca7f07166485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+------------------+----------------------------------------------+-------+\n",
            "|inp                                          |inpType           |out                                           |outType|\n",
            "+---------------------------------------------+------------------+----------------------------------------------+-------+\n",
            "|{name -> rahul, interest -> data engineering}|map<string,string>|{\"name\":\"rahul\",\"interest\":\"data engineering\"}|string |\n",
            "+---------------------------------------------+------------------+----------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_json (from an named_struct)\n",
        "\n",
        "sql = '''\n",
        "with cte as\n",
        "(\n",
        "select named_struct('name','rahul','interest','data engineering') as inp\n",
        ")\n",
        "select\n",
        "  inp,\n",
        "  typeOf(inp) as inpType,\n",
        "  to_json(inp) as out,\n",
        "  typeOf(to_json(inp)) as outType\n",
        "from cte\n",
        "'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoQ_lfCXZSBI",
        "outputId": "e37f57fa-85db-4ade-bceb-89a600da9a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+-----------------------------------+----------------------------------------------+-------+\n",
            "|inp                      |inpType                            |out                                           |outType|\n",
            "+-------------------------+-----------------------------------+----------------------------------------------+-------+\n",
            "|{rahul, data engineering}|struct<name:string,interest:string>|{\"name\":\"rahul\",\"interest\":\"data engineering\"}|string |\n",
            "+-------------------------+-----------------------------------+----------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_json (from an named_struct)\n",
        "\n",
        "sql = '''\n",
        "with cte as\n",
        "(\n",
        "select array(named_struct('name','rahul','interest','data engineering'),\n",
        "             named_struct('name','meghana','interest','data analysis')) as inp\n",
        ")\n",
        "select\n",
        "  inp,\n",
        "  typeOf(inp) as inpType,\n",
        "  to_json(inp) as out,\n",
        "  typeOf(to_json(inp)) as outType\n",
        "from cte\n",
        "'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqg-Bk4hazS4",
        "outputId": "bf610428-7468-4048-e34a-99b659aaef35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------+------------------------------------------+----------------------------------------------------------------------------------------------+-------+\n",
            "|inp                                                  |inpType                                   |out                                                                                           |outType|\n",
            "+-----------------------------------------------------+------------------------------------------+----------------------------------------------------------------------------------------------+-------+\n",
            "|[{rahul, data engineering}, {meghana, data analysis}]|array<struct<name:string,interest:string>>|[{\"name\":\"rahul\",\"interest\":\"data engineering\"},{\"name\":\"meghana\",\"interest\":\"data analysis\"}]|string |\n",
            "+-----------------------------------------------------+------------------------------------------+----------------------------------------------------------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_binary\n",
        "\n",
        "sql = '''SELECT to_binary(167) AS castedOut''' ## requires a formatting pattern\n",
        "spark.sql(sql).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXtuyK0RbQf0",
        "outputId": "10484039-36d4-442c-bb9a-68c97c54fe16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|castedOut|\n",
            "+---------+\n",
            "|[01 67]  |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}