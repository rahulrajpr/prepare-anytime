{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNyCGZc3FCmwYVKuuO8Auh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrajpr/prepare-anytime/blob/main/spark/functions/17_spark_dataframe_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark DataFrame Methods**\n",
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html"
      ],
      "metadata": {
        "id": "eXNLeR9Hs5y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdFsXh8rs4xn",
        "outputId": "b15b07da-7a46-4ade-9436-4f7dc0a8c9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "3.5.1\n"
          ]
        }
      ],
      "source": [
        "# Install Java and PySpark\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-11-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark -q\n",
        "\n",
        "# Set Java home\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "import pyspark\n",
        "print(pyspark.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP2j1TwH3q4d",
        "outputId": "b0e83c9e-a256-49a7-ae18-c797160bf78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('spark-dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "gxvP8Rgmts8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, DateType\n",
        "from pyspark.sql.functions import col, lit\n",
        "from datetime import datetime, date\n",
        "\n",
        "data = [\n",
        "    # Complete records\n",
        "    (1, \"Alice\", \"Engineering\", 75000.50, 28, True, date(2020, 1, 15), \"New York\"),\n",
        "    (2, \"Bob\", \"Marketing\", 65000.75, 32, False, date(2019, 3, 20), \"San Francisco\"),\n",
        "    (3, \"Charlie\", \"Engineering\", 82000.25, 35, True, date(2018, 7, 10), \"New York\"),\n",
        "    (4, \"Diana\", \"Sales\", 58000.00, 29, True, date(2021, 5, 5), \"Chicago\"),\n",
        "    (5, \"Eve\", \"HR\", 62000.80, 31, False, date(2020, 11, 30), \"Boston\"),\n",
        "\n",
        "    # Records with some null values\n",
        "    (6, \"Frank\", None, 71000.40, 40, True, date(2017, 8, 25), None),\n",
        "    (7, None, \"Engineering\", 68000.60, 27, False, date(2022, 2, 14), \"Seattle\"),\n",
        "    (8, \"Grace\", \"Marketing\", None, 33, True, date(2019, 9, 8), \"Austin\"),\n",
        "    (9, \"Henry\", \"Sales\", 59000.90, None, False, date(2021, 12, 1), \"Denver\"),\n",
        "    (10, \"Ivy\", \"HR\", 63000.30, 36, None, None, \"Portland\"),\n",
        "\n",
        "    # Edge cases\n",
        "    (11, \"\", \"Engineering\", 0.0, 0, False, date(2023, 1, 1), \"\"),\n",
        "    (12, \"Jack\", \"Sales\", 1000000.99, 99, True, date(2015, 12, 31), \"Miami\"),\n",
        "    (13, \"Karen\", \"Marketing\", 45000.00, 22, True, date(2023, 6, 15), \"Atlanta\"),\n",
        "    (14, \"Leo\", \"Engineering\", 95000.00, 45, False, date(2016, 4, 18), \"New York\"),\n",
        "    (15, \"Mona\", None, 52000.50, 26, True, date(2022, 8, 9), \"Chicago\")\n",
        "]\n",
        "\n",
        "# Define schema\n",
        "schema = StructType([\n",
        "    StructField(\"employee_id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"department\", StringType(), True),\n",
        "    StructField(\"salary\", DoubleType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"is_active\", BooleanType(), True),\n",
        "    StructField(\"hire_date\", DateType(), True),\n",
        "    StructField(\"city\", StringType(), True)\n",
        "])\n",
        "\n",
        "dataframe = spark.createDataFrame(data, schema)\n",
        "dataframe.printSchema()\n",
        "dataframe.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEzrQgaiuHLl",
        "outputId": "6ef9723b-c511-4d03-c04b-c0d546ca0032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- is_active: boolean (nullable = true)\n",
            " |-- hire_date: date (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            "\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show : return a dataframe into the console\n",
        "\n",
        "dataframe.show(n = 10, truncate = False, vertical=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL_JdwQJuhrc",
        "outputId": "58dc8b4c-3f6b-4b1a-dfe8-79157df12c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4 |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6 |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL    |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9 |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3 |36  |NULL     |NULL      |Portland     |\n",
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first() : return the pyspark row\n",
        "\n",
        "print(type(dataframe.first()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy8STV0MCoWb",
        "outputId": "241a66a4-9880-4761-bc8c-e15ac5458b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.types.Row'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# head() : returns a list of pyspark row\n",
        "\n",
        "print(type(dataframe.head(2)),'\\n')\n",
        "dataframe.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBND-QMUBi3b",
        "outputId": "ccc041d3-9815-4341-f08e-228b3cdda28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(employee_id=1, name='Alice', department='Engineering', salary=75000.5, age=28, is_active=True, hire_date=datetime.date(2020, 1, 15), city='New York'),\n",
              " Row(employee_id=2, name='Bob', department='Marketing', salary=65000.75, age=32, is_active=False, hire_date=datetime.date(2019, 3, 20), city='San Francisco')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take : returns a list of pyspark row\n",
        "\n",
        "print(type(dataframe.take(2)),'\\n')\n",
        "dataframe.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKDS-MnVB7a0",
        "outputId": "4051061a-436d-43c5-ac3d-e91a30b2d7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(employee_id=1, name='Alice', department='Engineering', salary=75000.5, age=28, is_active=True, hire_date=datetime.date(2020, 1, 15), city='New York'),\n",
              " Row(employee_id=2, name='Bob', department='Marketing', salary=65000.75, age=32, is_active=False, hire_date=datetime.date(2019, 3, 20), city='San Francisco')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect\n",
        "\n",
        "# take : returns a list of pyspark row, BUT all the rows in a dataframe\n",
        "\n",
        "dataframe.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN-e2kvBDQ5B",
        "outputId": "1cc7b840-a5c0-489b-e832-6524682e2ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(employee_id=1, name='Alice', department='Engineering', salary=75000.5, age=28, is_active=True, hire_date=datetime.date(2020, 1, 15), city='New York'),\n",
              " Row(employee_id=2, name='Bob', department='Marketing', salary=65000.75, age=32, is_active=False, hire_date=datetime.date(2019, 3, 20), city='San Francisco'),\n",
              " Row(employee_id=3, name='Charlie', department='Engineering', salary=82000.25, age=35, is_active=True, hire_date=datetime.date(2018, 7, 10), city='New York'),\n",
              " Row(employee_id=4, name='Diana', department='Sales', salary=58000.0, age=29, is_active=True, hire_date=datetime.date(2021, 5, 5), city='Chicago'),\n",
              " Row(employee_id=5, name='Eve', department='HR', salary=62000.8, age=31, is_active=False, hire_date=datetime.date(2020, 11, 30), city='Boston'),\n",
              " Row(employee_id=6, name='Frank', department=None, salary=71000.4, age=40, is_active=True, hire_date=datetime.date(2017, 8, 25), city=None),\n",
              " Row(employee_id=7, name=None, department='Engineering', salary=68000.6, age=27, is_active=False, hire_date=datetime.date(2022, 2, 14), city='Seattle'),\n",
              " Row(employee_id=8, name='Grace', department='Marketing', salary=None, age=33, is_active=True, hire_date=datetime.date(2019, 9, 8), city='Austin'),\n",
              " Row(employee_id=9, name='Henry', department='Sales', salary=59000.9, age=None, is_active=False, hire_date=datetime.date(2021, 12, 1), city='Denver'),\n",
              " Row(employee_id=10, name='Ivy', department='HR', salary=63000.3, age=36, is_active=None, hire_date=None, city='Portland'),\n",
              " Row(employee_id=11, name='', department='Engineering', salary=0.0, age=0, is_active=False, hire_date=datetime.date(2023, 1, 1), city=''),\n",
              " Row(employee_id=12, name='Jack', department='Sales', salary=1000000.99, age=99, is_active=True, hire_date=datetime.date(2015, 12, 31), city='Miami'),\n",
              " Row(employee_id=13, name='Karen', department='Marketing', salary=45000.0, age=22, is_active=True, hire_date=datetime.date(2023, 6, 15), city='Atlanta'),\n",
              " Row(employee_id=14, name='Leo', department='Engineering', salary=95000.0, age=45, is_active=False, hire_date=datetime.date(2016, 4, 18), city='New York'),\n",
              " Row(employee_id=15, name='Mona', department=None, salary=52000.5, age=26, is_active=True, hire_date=datetime.date(2022, 8, 9), city='Chicago')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Method    | Returns                    | Usage Example    | Notes                          |\n",
        "|-----------|----------------------------|------------------|--------------------------------|\n",
        "| `first()` | First row as Row object    | `df.first()`     | Same as `head(1)[0]`           |\n",
        "| `head()`  | First row (or n rows)      | `df.head()` or `df.head(5)` | Default returns first row only |\n",
        "| `take(n)` | First n rows as list       | `df.take(3)`     | Returns list of Row objects    |\n",
        "| `collect()`| All rows as list          | `df.collect()`   | ‚ö†Ô∏è Brings ALL data to driver  |\n",
        "|\n",
        "# **üö® IMPORTANT: All of these methods are ACTIONS - they trigger computation and bring data from executors to the driver!**"
      ],
      "metadata": {
        "id": "2YU6ZVaAEzKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# isEmpty()\n",
        "\n",
        "dataframe.isEmpty()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzshA72_Dk1s",
        "outputId": "421b925c-dc1d-4333-a0c7-af5cae68808e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count\n",
        "\n",
        "dataframe.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnI0FyGEFSwA",
        "outputId": "81127464-b370-4563-f36f-05aa382f124a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printSchema() : printing the schema into the console\n",
        "\n",
        "dataframe.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5XjI5beFXHW",
        "outputId": "0b0ac452-cdfd-4a26-8fef-a8f8a8ad7186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- is_active: boolean (nullable = true)\n",
            " |-- hire_date: date (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# schema\n",
        "\n",
        "# it is not a method, it is an attibute of the dataframe object\n",
        "\n",
        "dataframe.schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytG2HESMFcBO",
        "outputId": "772e9f78-6b0b-4fc9-9dcd-cad678460239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('employee_id', IntegerType(), True), StructField('name', StringType(), True), StructField('department', StringType(), True), StructField('salary', DoubleType(), True), StructField('age', IntegerType(), True), StructField('is_active', BooleanType(), True), StructField('hire_date', DateType(), True), StructField('city', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dtypes\n",
        "\n",
        "# it is not a method, it is an attibute of the dataframe object\n",
        "\n",
        "dataframe.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk4yS_8JFhmU",
        "outputId": "bbcc22de-b836-4c32-c774-2a3cf3a98029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('employee_id', 'int'),\n",
              " ('name', 'string'),\n",
              " ('department', 'string'),\n",
              " ('salary', 'double'),\n",
              " ('age', 'int'),\n",
              " ('is_active', 'boolean'),\n",
              " ('hire_date', 'date'),\n",
              " ('city', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# columns\n",
        "\n",
        "# it is not a method, it is an attibute of the dataframe object\n",
        "\n",
        "dataframe.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ms2yueF29S",
        "outputId": "7f835ffb-49ea-4389-d3a7-4af391475e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['employee_id',\n",
              " 'name',\n",
              " 'department',\n",
              " 'salary',\n",
              " 'age',\n",
              " 'is_active',\n",
              " 'hire_date',\n",
              " 'city']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# describe()\n",
        "\n",
        "dataframe.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd0rUZQmF95n",
        "outputId": "6202a159-c722-4a3a-fcab-c8fae5e57f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, employee_id: string, name: string, department: string, salary: string, age: string, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "\n",
        "dataframe.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbmshzLPGI2L",
        "outputId": "bbb8cfc4-6aa9-4469-ff8c-330e78a89e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, employee_id: string, name: string, department: string, salary: string, age: string, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Note : Describe and Summary gives you the same information"
      ],
      "metadata": {
        "id": "Zxuz_RmOGd5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select\n",
        "\n",
        "dataframe.select('*').show(n = 2)\n",
        "dataframe.select('employee_id','name').show(n = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL8ANO83GbA8",
        "outputId": "c5790a89-fd67-4521-a6c9-1202618657d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id| name| department|  salary|age|is_active| hire_date|         city|\n",
            "+-----------+-----+-----------+--------+---+---------+----------+-------------+\n",
            "|          1|Alice|Engineering| 75000.5| 28|     true|2020-01-15|     New York|\n",
            "|          2|  Bob|  Marketing|65000.75| 32|    false|2019-03-20|San Francisco|\n",
            "+-----------+-----+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+-----------+-----+\n",
            "|employee_id| name|\n",
            "+-----------+-----+\n",
            "|          1|Alice|\n",
            "|          2|  Bob|\n",
            "+-----------+-----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selectExpr\n",
        "\n",
        "dataframe.selectExpr('employee_id','upper(name) as upperName').show(2)\n",
        "dataframe.selectExpr('employee_id','''name||'-'|| department as name_and_department''').show(2, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yynDOoM8Gy34",
        "outputId": "7b46a5e0-8f5c-44e4-c9dd-a90638498a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+\n",
            "|employee_id|upperName|\n",
            "+-----------+---------+\n",
            "|          1|    ALICE|\n",
            "|          2|      BOB|\n",
            "+-----------+---------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+-----------+-------------------+\n",
            "|employee_id|name_and_department|\n",
            "+-----------+-------------------+\n",
            "|1          |Alice-Engineering  |\n",
            "|2          |Bob-Marketing      |\n",
            "+-----------+-------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# colRegex() : to find the iterrator for columns what align to a string regex patten, and is used along with select method to fetch certain columns dynamically\n",
        "\n",
        "colsToSelect = dataframe.colRegex(\"`[a,c].*`\")\n",
        "print('\\n',colsToSelect,'\\n')\n",
        "\n",
        "dataframe.select(colsToSelect).show(2, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxGk44ahHGE9",
        "outputId": "a22bbe4b-b878-4aa6-cca4-d52af543d4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Column<'unresolvedregex()'> \n",
            "\n",
            "+---+-------------+\n",
            "|age|city         |\n",
            "+---+-------------+\n",
            "|28 |New York     |\n",
            "|32 |San Francisco|\n",
            "+---+-------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# withColumn()\n",
        "\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "dataframe.withColumn('name_and_departmenmt', expr('''name ||'-'|| department as name_department''')).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKT5A6qSH0TL",
        "outputId": "eba338d9-9ec3-4ec7-945d-3e72f4b513a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+--------------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |name_and_departmenmt|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+--------------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |Alice-Engineering   |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|Bob-Marketing       |\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |Charlie-Engineering |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |Diana-Sales         |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |Eve-HR              |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# withColumns()\n",
        "\n",
        "dataframe.withColumns({'upperName':expr('upper(name)'),\n",
        "                       'is_active_binary': expr('case when is_active = True then 1 else 0 end')})\\\n",
        "                       .show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSCclE0uJ7S9",
        "outputId": "c30c0efd-4a4c-4b74-afef-b010da17b72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+---------+----------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |upperName|is_active_binary|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+---------+----------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |ALICE    |1               |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|BOB      |0               |\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |CHARLIE  |1               |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |DIANA    |1               |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |EVE      |0               |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+---------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# withColumnRenamed\n",
        "\n",
        "dataframe.withColumnRenamed('name','employee').show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttcm-7M2NXW7",
        "outputId": "c25977a8-c29b-44e0-bef3-a28feedfd7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|employee|department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+--------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice   |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob     |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie |Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana   |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve     |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "+-----------+--------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# withColumnsRenamed\n",
        "\n",
        "dataframe.withColumnsRenamed({'name':'employee',\n",
        "                              'hire_date':'joiningDate'}).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uETh5E4SN5Pe",
        "outputId": "7c2d8701-c337-406c-b0a9-586899d212e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+-----------+--------+---+---------+-----------+-------------+\n",
            "|employee_id|employee|department |salary  |age|is_active|joiningDate|city         |\n",
            "+-----------+--------+-----------+--------+---+---------+-----------+-------------+\n",
            "|1          |Alice   |Engineering|75000.5 |28 |true     |2020-01-15 |New York     |\n",
            "|2          |Bob     |Marketing  |65000.75|32 |false    |2019-03-20 |San Francisco|\n",
            "|3          |Charlie |Engineering|82000.25|35 |true     |2018-07-10 |New York     |\n",
            "|4          |Diana   |Sales      |58000.0 |29 |true     |2021-05-05 |Chicago      |\n",
            "|5          |Eve     |HR         |62000.8 |31 |false    |2020-11-30 |Boston       |\n",
            "+-----------+--------+-----------+--------+---+---------+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop\n",
        "\n",
        "dataframe.drop('salary').show(5, truncate = False)\n",
        "\n",
        "dataframe.drop('salary','age').show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhEbHFK7OU4z",
        "outputId": "e46e41e7-4eda-4783-b063-0a32d978f14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |31 |false    |2020-11-30|Boston       |\n",
            "+-----------+-------+-----------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+---------+----------+-------------+\n",
            "|employee_id|name   |department |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |false    |2020-11-30|Boston       |\n",
            "+-----------+-------+-----------+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "dataframe.filter(col('department').eqNullSafe(lit('Engineering'))).show(5, truncate = False)\n",
        "\n",
        "dataframe.filter(expr('''department = 'Engineering' ''')).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "868LhtwbOuCh",
        "outputId": "baa822c5-0235-42a6-c0e8-380bc8e90824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# where\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "dataframe.where(col('department').eqNullSafe(lit('Engineering'))).show(5, truncate = False)\n",
        "\n",
        "dataframe.where(expr('''department = 'Engineering' ''')).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2uvhjO9PM8x",
        "outputId": "daa94978-4c72-4913-a189-43207a79856c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note : where is simply an alias for filter"
      ],
      "metadata": {
        "id": "0a6r3NQrQ_1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sort\n",
        "\n",
        "from pyspark.sql.functions import asc_nulls_last\n",
        "\n",
        "dataframe.sort(asc_nulls_last('department')).show(5, truncate = False)\n",
        "dataframe.sort(asc_nulls_last('department'),asc_nulls_last('name')).show(5, truncate = False)\n",
        "\n",
        "# dataframe.sort(expr('''department asc nulls last, name asc nulls last''')).show(5, truncate = False) -- THIS DOES NOT WORK, as expr does not support nulls last\n",
        "# sorting with multiple columns are not supported by expr anyways"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEAs3WalQ7ET",
        "outputId": "e9ad455b-dde1-404b-cc0c-9dbe1068b15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# orderBy\n",
        "\n",
        "from pyspark.sql.functions import asc_nulls_last\n",
        "\n",
        "dataframe.orderBy(asc_nulls_last('department')).show(5, truncate = False)\n",
        "dataframe.orderBy(asc_nulls_last('department'),asc_nulls_last('name')).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cJvM4aRRleQ",
        "outputId": "626f2af6-6046-446e-b6eb-b9eb9e73a163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sortWithinPartitions\n",
        "\n",
        "dataframe.sortWithinPartitions('department').show(5, truncate = False)\n",
        "dataframe.sortWithinPartitions(asc_nulls_last('department')).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpAOXJHOTfdc",
        "outputId": "b9fc870b-4d32-4f8a-bde3-f0534d32b796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|6          |Frank  |NULL       |71000.4 |40 |true     |2017-08-25|NULL    |\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston  |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Aspect          | `sort()`                           | `orderBy()`                       | `sortWithinPartitions()`          |\n",
        "|-----------------|------------------------------------|-----------------------------------|-----------------------------------|\n",
        "| **Purpose**     | Global sorting across all data     | Alias for `sort()` - same function| Sort data within each partition   |\n",
        "| **Scope**       | **Global** - entire dataset        | **Global** - entire dataset       | **Local** - per partition         |\n",
        "| **Performance** | Slower (full shuffle)              | Same as `sort()`                  | Faster (no shuffle)               |\n",
        "| **Use Case**    | Need total order across partitions | Same as `sort()`                  | Order matters within partitions   |"
      ],
      "metadata": {
        "id": "EXGJAAQ1UwrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  limit : it returns a dataframe, but the show return the output to the console\n",
        "\n",
        "dataframe.limit(10).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiKzxnVCUMO-",
        "outputId": "23c858c8-791d-47d0-8567-13fc4486bb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4 |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6 |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL    |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9 |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3 |36  |NULL     |NULL      |Portland     |\n",
            "+-----------+-------+-----------+--------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# offset\n",
        "\n",
        "dataframe.offset(10).show(truncate = False)\n",
        "\n",
        "## a fancy operation to lookat\n",
        "\n",
        "dataframe.offset(10).limit(3).filter(~col('name').eqNullSafe('')).select('employee_id','name').show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW0TDe8BVC99",
        "outputId": "270b49ea-c478-4ae6-85bb-1a716e148894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-----------+----------+---+---------+----------+--------+\n",
            "|employee_id|name |department |salary    |age|is_active|hire_date |city    |\n",
            "+-----------+-----+-----------+----------+---+---------+----------+--------+\n",
            "|11         |     |Engineering|0.0       |0  |false    |2023-01-01|        |\n",
            "|12         |Jack |Sales      |1000000.99|99 |true     |2015-12-31|Miami   |\n",
            "|13         |Karen|Marketing  |45000.0   |22 |true     |2023-06-15|Atlanta |\n",
            "|14         |Leo  |Engineering|95000.0   |45 |false    |2016-04-18|New York|\n",
            "|15         |Mona |NULL       |52000.5   |26 |true     |2022-08-09|Chicago |\n",
            "+-----------+-----+-----------+----------+---+---------+----------+--------+\n",
            "\n",
            "+-----------+-----+\n",
            "|employee_id|name |\n",
            "+-----------+-----+\n",
            "|12         |Jack |\n",
            "|13         |Karen|\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distinct\n",
        "\n",
        "dataframe.distinct().show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teRgTf9cVlOj",
        "outputId": "3f28d023-7e14-413d-8e52-458a9e5eeb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropDuplicates\n",
        "\n",
        "dataframe.dropDuplicates().show(5, truncate = False)\n",
        "\n",
        "dataframe.dropDuplicates(['department','city']).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOjobK7AWZNw",
        "outputId": "8654b938-85ca-47c5-cfed-3511099ec67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-----+-----------+-------+---+---------+----------+--------+\n",
            "|employee_id|name |department |salary |age|is_active|hire_date |city    |\n",
            "+-----------+-----+-----------+-------+---+---------+----------+--------+\n",
            "|6          |Frank|NULL       |71000.4|40 |true     |2017-08-25|NULL    |\n",
            "|15         |Mona |NULL       |52000.5|26 |true     |2022-08-09|Chicago |\n",
            "|11         |     |Engineering|0.0    |0  |false    |2023-01-01|        |\n",
            "|1          |Alice|Engineering|75000.5|28 |true     |2020-01-15|New York|\n",
            "|7          |NULL |Engineering|68000.6|27 |false    |2022-02-14|Seattle |\n",
            "+-----------+-----+-----------+-------+---+---------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Aspect | `distinct()` | `dropDuplicates()` |\n",
        "|--------|--------------|-------------------|\n",
        "| **What it does** | Returns distinct **rows** across all columns | Returns distinct rows, can specify columns |\n",
        "| **Column scope** | **All columns** only | **All columns** OR **specific columns** |\n",
        "| **Usage** | `df.distinct()` | `df.dropDuplicates()` or `df.dropDuplicates(['col1','col2'])` |\n",
        "| **Performance** | Same (both cause shuffles) | Same (both cause shuffles) |\n",
        "| **Result** | Unique rows based on all columns | Unique rows based on specified columns |"
      ],
      "metadata": {
        "id": "N3aHSSxEYPDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# na\n",
        "# it is not a full method, it is infact an accessor to othe sub methods\n",
        "\n",
        "dataframe.na.drop(how = 'all').show(8, truncate=False)\n",
        "dataframe.na.fill('Missing').show(8, truncate=False)\n",
        "\n",
        "dataframe.na.replace('',None).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WC9kI8rXVHm",
        "outputId": "836fa8c1-0238-4c18-cfbd-21722c0cf243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4 |40 |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL    |33 |true     |2019-09-08|Austin       |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 8 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |Missing    |71000.4 |40 |true     |2017-08-25|Missing      |\n",
            "|7          |Missing|Engineering|68000.6 |27 |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL    |33 |true     |2019-09-08|Austin       |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 8 rows\n",
            "\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |NULL   |Engineering|0.0       |0   |false    |2023-01-01|NULL         |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Method | Purpose |\n",
        "|--------|---------|\n",
        "| `.na.fill()` | Replace **nulls** with values |\n",
        "| `.na.drop()` | Remove **null** rows |\n",
        "| `.na.replace()` | Replace **non-null values** with other values |\n",
        "\n",
        "So `.na.replace()` is for **changing existing data values**, not for handling missing data!"
      ],
      "metadata": {
        "id": "UlF5NOqMa-Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import NullType\n",
        "\n",
        "dataframe.fillna('missing').show(truncate = False)\n",
        "dataframe.na.replace('',None).fillna('missing').show(truncate = False)"
      ],
      "metadata": {
        "id": "ZZCHOiZjYrXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f19e4a-3c23-4cb7-ccee-1b0bcd3bbcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |missing    |71000.4   |40  |true     |2017-08-25|missing      |\n",
            "|7          |missing|Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |missing    |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |missing    |71000.4   |40  |true     |2017-08-25|missing      |\n",
            "|7          |missing|Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |missing|Engineering|0.0       |0   |false    |2023-01-01|missing      |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |missing    |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : `DataFame.na.fill()` and `DataFrame.fillna()` both are same methods in terms of the functionality"
      ],
      "metadata": {
        "id": "HCHLN67QEUS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropna\n",
        "\n",
        "dataframe.dropna().show(5,truncate = False)\n",
        "dataframe.dropna(how = 'all').show(5,truncate = False)\n",
        "dataframe.dropna(subset = ['name']).show(5,truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk1_dgk3CybE",
        "outputId": "5dd53b4d-1e68-47a7-f2c3-0456fd6d243b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75|32 |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0 |29 |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8 |31 |false    |2020-11-30|Boston       |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : `DataFrame.na.drop` and `DataFrame.dropna` are the same methods in terms of the functionality"
      ],
      "metadata": {
        "id": "Q1_WsMHtFDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# groupBy\n",
        "\n",
        "# Note : counnt as a method and count as function.\n",
        "# count() method : row counts\n",
        "# count function within agg methos, can count and expression or column with only non-null values\n",
        "\n",
        "from pyspark.sql.functions import count\n",
        "\n",
        "dataframe.groupBy('department').count().show() ## not possible to give alias directly\n",
        "\n",
        "dataframe.groupBy('department').count().withColumnRenamed('count','name_count').show()\n",
        "\n",
        "dataframe.groupBy('department').agg(count(col('name')).alias('name_count')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2yczQ2YEuI0",
        "outputId": "36f1caf0-e533-400e-846a-79d2bd1b91f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "| department|count|\n",
            "+-----------+-----+\n",
            "|      Sales|    3|\n",
            "|Engineering|    5|\n",
            "|         HR|    2|\n",
            "|       NULL|    2|\n",
            "|  Marketing|    3|\n",
            "+-----------+-----+\n",
            "\n",
            "+-----------+----------+\n",
            "| department|name_count|\n",
            "+-----------+----------+\n",
            "|      Sales|         3|\n",
            "|Engineering|         5|\n",
            "|         HR|         2|\n",
            "|       NULL|         2|\n",
            "|  Marketing|         3|\n",
            "+-----------+----------+\n",
            "\n",
            "+-----------+----------+\n",
            "| department|name_count|\n",
            "+-----------+----------+\n",
            "|      Sales|         3|\n",
            "|Engineering|         4|\n",
            "|         HR|         2|\n",
            "|       NULL|         2|\n",
            "|  Marketing|         3|\n",
            "+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agg\n",
        "\n",
        "from pyspark.sql.functions import expr,sum, avg\n",
        "\n",
        "dataframe.agg(expr('sum(salary) as total_salary'),expr(('avg(salary) as avg_salary'))).show(truncate = False)\n",
        "\n",
        "dataframe.agg(sum('salary').alias('total_salary'),avg('salary').alias('avg_salary')).show(truncate = False)\n",
        "\n",
        "dataframe.select(sum('salary').alias('total_salary'),avg('salary').alias('avg_salary')).show(truncate = False) ## select also can produce the same result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVLqFOG5FV9u",
        "outputId": "720a0068-bcc8-498a-c8cd-74e7b01291d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|total_salary      |avg_salary        |\n",
            "+------------------+------------------+\n",
            "|1795005.9899999998|128214.71357142855|\n",
            "+------------------+------------------+\n",
            "\n",
            "+------------------+------------------+\n",
            "|total_salary      |avg_salary        |\n",
            "+------------------+------------------+\n",
            "|1795005.9899999998|128214.71357142855|\n",
            "+------------------+------------------+\n",
            "\n",
            "+------------------+------------------+\n",
            "|total_salary      |avg_salary        |\n",
            "+------------------+------------------+\n",
            "|1795005.9899999998|128214.71357142855|\n",
            "+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# groupBy + agg\n",
        "\n",
        "from pyspark.sql.functions import expr,sum, avg\n",
        "\n",
        "dataframe.groupBy('department').agg(expr('sum(salary) as total_salary'),expr(('avg(salary) as avg_salary'))).show(truncate = False)\n",
        "\n",
        "dataframe.groupBy('department').agg(sum('salary').alias('total_salary'),avg('salary').alias('avg_salary')).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7IDeRiMUFEl",
        "outputId": "2cf5da06-aeee-4175-b0d5-9a37fb7eb69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------------+\n",
            "|department |total_salary|avg_salary       |\n",
            "+-----------+------------+-----------------+\n",
            "|Sales      |1117001.89  |372333.9633333333|\n",
            "|Engineering|320001.35   |64000.27         |\n",
            "|HR         |125001.1    |62500.55         |\n",
            "|NULL       |123000.9    |61500.45         |\n",
            "|Marketing  |110000.75   |55000.375        |\n",
            "+-----------+------------+-----------------+\n",
            "\n",
            "+-----------+------------+-----------------+\n",
            "|department |total_salary|avg_salary       |\n",
            "+-----------+------------+-----------------+\n",
            "|Sales      |1117001.89  |372333.9633333333|\n",
            "|Engineering|320001.35   |64000.27         |\n",
            "|HR         |125001.1    |62500.55         |\n",
            "|NULL       |123000.9    |61500.45         |\n",
            "|Marketing  |110000.75   |55000.375        |\n",
            "+-----------+------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "* For aggregation operations on the entire DataFrame (without grouping), `agg()` and `select()` can be used interchangeably and produce identical results\n",
        "* After `groupBy()`, you can only use `agg()` for aggregations - the `select()` method is not available on `GroupedData` objects\n",
        "* `groupBy()` returns a `GroupedData` object which has different methods available than a regular `DataFrame`"
      ],
      "metadata": {
        "id": "RjOQipAbWA7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rollup\n",
        "\n",
        "from pyspark.sql.functions import asc_nulls_last, desc_nulls_last\n",
        "\n",
        "dataframe.rollup(['department']).agg(count('name').alias('rollupCount'))\\\n",
        "         .sort(asc_nulls_last('department'))\\\n",
        "         .show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwqEfBnOVypG",
        "outputId": "8fe1fb18-af95-467a-ecae-b06f116f7077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|department |rollupCount|\n",
            "+-----------+-----------+\n",
            "|Engineering|4          |\n",
            "|HR         |2          |\n",
            "|Marketing  |3          |\n",
            "|Sales      |3          |\n",
            "|NULL       |2          |\n",
            "|NULL       |14         |\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rollup + grouping + grouping_id\n",
        "\n",
        "from pyspark.sql.functions import grouping, grouping_id, desc\n",
        "\n",
        "dataframe.rollup(['department'])\\\n",
        "         .agg(\n",
        "              count('name').alias('rollupCount'),\\\n",
        "              grouping_id().alias('grouping_id'),\n",
        "              grouping('department').alias('department_grouping')\n",
        "              )\\\n",
        "         .sort(asc_nulls_last('department'))\\\n",
        "         .show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGvliDKPXU7j",
        "outputId": "47a130a9-a157-4bd0-8d2e-3edaf1806a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-----------+-------------------+\n",
            "|department |rollupCount|grouping_id|department_grouping|\n",
            "+-----------+-----------+-----------+-------------------+\n",
            "|Engineering|4          |0          |0                  |\n",
            "|HR         |2          |0          |0                  |\n",
            "|Marketing  |3          |0          |0                  |\n",
            "|Sales      |3          |0          |0                  |\n",
            "|NULL       |2          |0          |0                  |\n",
            "|NULL       |14         |1          |1                  |\n",
            "+-----------+-----------+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Spark DataFrame** : `groupBy()` vs `rollup()`\n",
        "\n",
        "| Feature | `groupBy()` | `rollup()` |\n",
        "|---------|-------------|------------|\n",
        "| **Basic Purpose** | Groups data by specified columns for aggregation | Creates hierarchical subtotals and grand total |\n",
        "| **Output Levels** | Single level of aggregation | Multiple levels (detailed ‚Üí subtotals ‚Üí grand total) |\n",
        "| **Number of Result Rows** | One row per unique combination of grouping columns | Multiple rows per combination (n+1 levels where n=number of columns) |\n",
        "| **NULL Handling** | NULLs are treated as distinct groups | NULLs represent aggregated levels |\n",
        "| **Performance** | Faster for simple groupings | More expensive due to multiple aggregation levels |\n",
        "| **Use Cases** | Simple aggregations, distinct counts | Financial reports, hierarchical data, business intelligence |\n",
        "| **Syntax** | `df.groupBy(\"col1\", \"col2\").agg(...)` | `df.rollup(\"col1\", \"col2\").agg(...)` |\n",
        "| **Grouping ID** | Not applicable (always 0) | Essential for identifying aggregation levels |"
      ],
      "metadata": {
        "id": "10HMOhAua1Ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`grouping(col)`\n",
        "\n",
        "* Returns 1 if the column is aggregated (NULL in result)\n",
        "* Returns 0 if the column is present in the current grouping level\n",
        "* Used to identify which specific columns are aggregated\n",
        "\n",
        "`grouping_id()`\n",
        "\n",
        "* Returns a bitmask (integer) representing the aggregation level\n",
        "* Each bit corresponds to a column in rollup/cube (in reverse order)\n",
        "* 0 = column present, 1 = column aggregated\n",
        "* More efficient than multiple grouping() calls\n",
        "\n",
        "`Simple Rule:`\n",
        "\n",
        "* Use grouping(col) to check individual columns\n",
        "* Use grouping_id() to identify the complete aggregation level\n",
        "* Essential for working with rollup() and cube() operations"
      ],
      "metadata": {
        "id": "VeftjD6abTdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cube\n",
        "\n",
        "print('--rollup--\\n')\n",
        "\n",
        "dataframe.rollup('department', 'city')\\\n",
        "         .agg(count('name').alias('count_names'),\n",
        "              grouping_id().alias('grouping_id'),\n",
        "              grouping('department').alias('grouping_department'),\n",
        "              grouping('city').alias('grouping_id_city'))\\\n",
        "         .orderBy(asc_nulls_last('department'),asc_nulls_last('city'))\\\n",
        "         .show(truncate = False)\n",
        "\n",
        "print('--cube--\\n')\n",
        "\n",
        "dataframe.cube('department', 'city')\\\n",
        "         .agg(count('name').alias('count_names'),\n",
        "              grouping_id().alias('grouping_id'),\n",
        "              grouping('department').alias('grouping_department'),\n",
        "              grouping('city').alias('grouping_id_city'))\\\n",
        "         .orderBy(asc_nulls_last('department'),asc_nulls_last('city'))\\\n",
        "         .show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBBLoG4dZSV-",
        "outputId": "d71340ff-7023-405c-9962-ce3f101ad612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--rollup--\n",
            "\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "|department |city         |count_names|grouping_id|grouping_department|grouping_id_city|\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "|Engineering|             |1          |0          |0                  |0               |\n",
            "|Engineering|New York     |3          |0          |0                  |0               |\n",
            "|Engineering|Seattle      |0          |0          |0                  |0               |\n",
            "|Engineering|NULL         |4          |1          |0                  |1               |\n",
            "|HR         |Boston       |1          |0          |0                  |0               |\n",
            "|HR         |Portland     |1          |0          |0                  |0               |\n",
            "|HR         |NULL         |2          |1          |0                  |1               |\n",
            "|Marketing  |Atlanta      |1          |0          |0                  |0               |\n",
            "|Marketing  |Austin       |1          |0          |0                  |0               |\n",
            "|Marketing  |San Francisco|1          |0          |0                  |0               |\n",
            "|Marketing  |NULL         |3          |1          |0                  |1               |\n",
            "|Sales      |Chicago      |1          |0          |0                  |0               |\n",
            "|Sales      |Denver       |1          |0          |0                  |0               |\n",
            "|Sales      |Miami        |1          |0          |0                  |0               |\n",
            "|Sales      |NULL         |3          |1          |0                  |1               |\n",
            "|NULL       |Chicago      |1          |0          |0                  |0               |\n",
            "|NULL       |NULL         |1          |0          |0                  |0               |\n",
            "|NULL       |NULL         |2          |1          |0                  |1               |\n",
            "|NULL       |NULL         |14         |3          |1                  |1               |\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "\n",
            "--cube--\n",
            "\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "|department |city         |count_names|grouping_id|grouping_department|grouping_id_city|\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "|Engineering|             |1          |0          |0                  |0               |\n",
            "|Engineering|New York     |3          |0          |0                  |0               |\n",
            "|Engineering|Seattle      |0          |0          |0                  |0               |\n",
            "|Engineering|NULL         |4          |1          |0                  |1               |\n",
            "|HR         |Boston       |1          |0          |0                  |0               |\n",
            "|HR         |Portland     |1          |0          |0                  |0               |\n",
            "|HR         |NULL         |2          |1          |0                  |1               |\n",
            "|Marketing  |Atlanta      |1          |0          |0                  |0               |\n",
            "|Marketing  |Austin       |1          |0          |0                  |0               |\n",
            "|Marketing  |San Francisco|1          |0          |0                  |0               |\n",
            "|Marketing  |NULL         |3          |1          |0                  |1               |\n",
            "|Sales      |Chicago      |1          |0          |0                  |0               |\n",
            "|Sales      |Denver       |1          |0          |0                  |0               |\n",
            "|Sales      |Miami        |1          |0          |0                  |0               |\n",
            "|Sales      |NULL         |3          |1          |0                  |1               |\n",
            "|NULL       |             |1          |2          |1                  |0               |\n",
            "|NULL       |Atlanta      |1          |2          |1                  |0               |\n",
            "|NULL       |Austin       |1          |2          |1                  |0               |\n",
            "|NULL       |Boston       |1          |2          |1                  |0               |\n",
            "|NULL       |Chicago      |2          |2          |1                  |0               |\n",
            "+-----------+-------------+-----------+-----------+-------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spark Grouping Methods\n",
        "\n",
        "| Feature | `groupBy()` | `rollup()` | `cube()` |\n",
        "|---------|-------------|------------|----------|\n",
        "| **Basic Purpose** | Simple grouping and aggregation | Hierarchical subtotals (drill-down) | All possible dimension combinations |\n",
        "| **Output Levels** | Single level - only specified combinations | Multiple hierarchical levels | All possible 2‚Åø combinations |\n",
        "| **Number of Results** | One row per unique group combination | n+1 levels per hierarchy | 2‚Åø combinations (exponential) |\n",
        "| **NULL Handling** | NULLs treated as regular values | NULLs represent aggregated levels | NULLs represent aggregated levels |\n",
        "| **Performance** | Fastest - minimal overhead | Moderate - multiple aggregation levels | Slowest - exponential combinations |\n",
        "| **Use Cases** | Basic reports, simple analytics | Financial reports, organizational hierarchies | Business intelligence, cross-analysis |\n",
        "| **Syntax** | `df.groupBy(\"A\",\"B\").agg(...)` | `df.rollup(\"A\",\"B\").agg(...)` | `df.cube(\"A\",\"B\").agg(...)` |\n",
        "| **Grouping ID** | Not needed (always detailed) | Essential for level identification | Essential for combination identification |\n",
        "| **Hierarchy** | Flat structure | Parent-child relationships | All dimensions independent |\n",
        "| **Mathematical Formula** | C(n, k) combinations | n+1 levels | 2‚Åø combinations |"
      ],
      "metadata": {
        "id": "whFer3QHhZNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SQL Grouping Methods Availability Across Databases\n",
        "\n",
        "| Database | `GROUP BY` | `ROLLUP` | `CUBE` | Syntax Notes |\n",
        "|----------|------------|----------|--------|--------------|\n",
        "| **SQL Server** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **PostgreSQL** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **MySQL** | ‚úÖ | ‚úÖ | ‚ùå | `GROUP BY a,b WITH ROLLUP` (limited) |\n",
        "| **Oracle** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Redshift** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Snowflake** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **BigQuery** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **SQLite** | ‚úÖ | ‚ùå | ‚ùå | Basic GROUP BY only |\n",
        "| **DB2** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Teradata** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Spark SQL** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Trino** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "| **Databricks** | ‚úÖ | ‚úÖ | ‚úÖ | `GROUP BY ROLLUP(a,b)`, `GROUP BY CUBE(a,b)` |\n",
        "\n",
        "## Additional Notes:\n",
        "\n",
        "### **Spark SQL:**\n",
        "- ‚úÖ Full ANSI SQL support for grouping operations\n",
        "- ‚úÖ Also available via DataFrame API: `df.rollup()`, `df.cube()`\n",
        "- ‚úÖ Supports `GROUPING SETS`, `GROUPING()`, `GROUPING_ID()`\n",
        "\n",
        "### **Trino (formerly PrestoSQL):**\n",
        "- ‚úÖ Full ANSI SQL compliance\n",
        "- ‚úÖ Advanced grouping operations\n",
        "- ‚úÖ Excellent performance for analytical queries\n",
        "\n",
        "### **Databricks:**\n",
        "- ‚úÖ Built on Spark SQL - full feature parity\n",
        "- ‚úÖ Optimized for large-scale analytics\n",
        "- ‚úÖ Both SQL and DataFrame API support\n",
        "- ‚úÖ Enhanced performance on Databricks runtime\n",
        "\n",
        "## Complete Big Data Ecosystem Support:\n",
        "\n",
        "| Platform | SQL Syntax | DataFrame API | Performance | Use Case |\n",
        "|----------|------------|---------------|-------------|----------|\n",
        "| **Spark SQL** | ‚úÖ | ‚úÖ | üü° Good | General big data processing |\n",
        "| **Trino** | ‚úÖ | ‚ùå | üü¢ Excellent | Interactive analytics |\n",
        "| **Databricks** | ‚úÖ | ‚úÖ | üü¢ Excellent | Enterprise data analytics |"
      ],
      "metadata": {
        "id": "Xpt0HtwPmbWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .Groupby.pivot\n",
        "\n",
        "dataframe.groupBy('department').pivot('is_active').count().na.fill(0).show(truncate = False)\n",
        "\n",
        "dataframe.filter(expr('is_active IS NOT NULL'))\\\n",
        "         .groupBy('department')\\\n",
        "         .pivot('is_active')\\\n",
        "         .count()\\\n",
        "         .na.fill(0)\\\n",
        "         .show(truncate = False)\n",
        "\n",
        "pivotedDataframe = dataframe.filter(expr('is_active IS NOT NULL'))\\\n",
        "         .groupBy('department')\\\n",
        "         .pivot('is_active')\\\n",
        "         .agg(count(col('name')))\\\n",
        "         .na.fill(0)\\\n",
        "\n",
        "pivotedDataframe.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Pgh95Ecsw_",
        "outputId": "01bf5fc8-9efe-4ab6-e043-e9ca7d626f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+-----+----+\n",
            "|department |null|false|true|\n",
            "+-----------+----+-----+----+\n",
            "|Sales      |0   |1    |2   |\n",
            "|Engineering|0   |3    |2   |\n",
            "|HR         |1   |1    |0   |\n",
            "|NULL       |0   |0    |2   |\n",
            "|Marketing  |0   |1    |2   |\n",
            "+-----------+----+-----+----+\n",
            "\n",
            "+-----------+-----+----+\n",
            "|department |false|true|\n",
            "+-----------+-----+----+\n",
            "|Sales      |1    |2   |\n",
            "|Engineering|3    |2   |\n",
            "|HR         |1    |0   |\n",
            "|NULL       |0    |2   |\n",
            "|Marketing  |1    |2   |\n",
            "+-----------+-----+----+\n",
            "\n",
            "+-----------+-----+----+\n",
            "|department |false|true|\n",
            "+-----------+-----+----+\n",
            "|Sales      |1    |2   |\n",
            "|Engineering|2    |2   |\n",
            "|HR         |1    |0   |\n",
            "|NULL       |0    |2   |\n",
            "|Marketing  |1    |2   |\n",
            "+-----------+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note :\n",
        "* `Pivot` can only be used along with the `groupBy object`,\n",
        "* **NOT** with `rollup` or `cube object`"
      ],
      "metadata": {
        "id": "eOdWO6Xpp-4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unpivot\n",
        "\n",
        "from pyspark.sql.functions import col,lit\n",
        "\n",
        "pivotedDataframe.unpivot('department',['true','false'],'identifier','values').show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URXp7RRnpiVV",
        "outputId": "212cb1fd-20d2-4128-a698-e0b02218fe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------+\n",
            "|department |identifier|values|\n",
            "+-----------+----------+------+\n",
            "|Sales      |true      |2     |\n",
            "|Sales      |false     |1     |\n",
            "|Engineering|true      |2     |\n",
            "|Engineering|false     |2     |\n",
            "|HR         |true      |0     |\n",
            "|HR         |false     |1     |\n",
            "|NULL       |true      |2     |\n",
            "|NULL       |false     |0     |\n",
            "|Marketing  |true      |2     |\n",
            "|Marketing  |false     |1     |\n",
            "+-----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# melt\n",
        "\n",
        "from pyspark.sql.functions import col,lit\n",
        "\n",
        "pivotedDataframe.unpivot('department',['true','false'],'identifier','values').show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqQxPPmqrkd5",
        "outputId": "58e5eeeb-ff1f-4d42-cbb5-9f517ed65f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+------+\n",
            "|department |identifier|values|\n",
            "+-----------+----------+------+\n",
            "|Sales      |true      |2     |\n",
            "|Sales      |false     |1     |\n",
            "|Engineering|true      |2     |\n",
            "|Engineering|false     |2     |\n",
            "|HR         |true      |0     |\n",
            "|HR         |false     |1     |\n",
            "|NULL       |true      |2     |\n",
            "|NULL       |false     |0     |\n",
            "|Marketing  |true      |2     |\n",
            "|Marketing  |false     |1     |\n",
            "+-----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : melt and unpivot methods are functionally the same\n"
      ],
      "metadata": {
        "id": "qId43tnYtR_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crosstab\n",
        "\n",
        "dataframe.crosstab('department','is_active').show(truncate = False)\n",
        "\n",
        "dataframe.crosstab('department','city').show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVnuPOS5tMqj",
        "outputId": "35ffe2cc-dae6-4daf-e5c0-24636dfaa240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----+----+\n",
            "|department_is_active|false|null|true|\n",
            "+--------------------+-----+----+----+\n",
            "|Sales               |1    |0   |2   |\n",
            "|Engineering         |3    |0   |2   |\n",
            "|HR                  |1    |1   |0   |\n",
            "|Marketing           |1    |0   |2   |\n",
            "|null                |0    |0   |2   |\n",
            "+--------------------+-----+----+----+\n",
            "\n",
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "|department_city|   |Atlanta|Austin|Boston|Chicago|Denver|Miami|New York|Portland|San Francisco|Seattle|null|\n",
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "|Sales          |0  |0      |0     |0     |1      |1     |1    |0       |0       |0            |0      |0   |\n",
            "|Engineering    |1  |0      |0     |0     |0      |0     |0    |3       |0       |0            |1      |0   |\n",
            "|HR             |0  |0      |0     |1     |0      |0     |0    |0       |1       |0            |0      |0   |\n",
            "|Marketing      |0  |1      |1     |0     |0      |0     |0    |0       |0       |1            |0      |0   |\n",
            "|null           |0  |0      |0     |0     |1      |0     |0    |0       |0       |0            |0      |1   |\n",
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : `crosstab --> grouby.pivot.count()` , or let say frequency"
      ],
      "metadata": {
        "id": "MSAXDpesuUnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# join\n",
        "\n",
        "employees_data = [\n",
        "    (1, \"Alice\", \"IT\", 101),\n",
        "    (2, \"Bob\", \"HR\", 102),\n",
        "    (3, \"Charlie\", \"IT\", 101),\n",
        "    (4, \"Diana\", \"Finance\", 103)\n",
        "]\n",
        "employees_df = spark.createDataFrame(employees_data, [\"emp_id\", \"name\", \"dept\", \"dept_id\"])\n",
        "\n",
        "departments_data = [\n",
        "    (101, \"IT\", \"New York\"),\n",
        "    (102, \"HR\", \"Chicago\"),\n",
        "    (103, \"Finance\", \"Boston\"),\n",
        "    (104, \"Marketing\", \"Seattle\")\n",
        "]\n",
        "departments_df = spark.createDataFrame(departments_data, [\"dept_id\", \"dept_name\", \"location\"])\n",
        "\n",
        "employees_df.show()\n",
        "\n",
        "departments_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1UoycWvuLJo",
        "outputId": "cff15e4a-8262-4029-a3a1-e7358cc3a11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+-------+\n",
            "|emp_id|   name|   dept|dept_id|\n",
            "+------+-------+-------+-------+\n",
            "|     1|  Alice|     IT|    101|\n",
            "|     2|    Bob|     HR|    102|\n",
            "|     3|Charlie|     IT|    101|\n",
            "|     4|  Diana|Finance|    103|\n",
            "+------+-------+-------+-------+\n",
            "\n",
            "+-------+---------+--------+\n",
            "|dept_id|dept_name|location|\n",
            "+-------+---------+--------+\n",
            "|    101|       IT|New York|\n",
            "|    102|       HR| Chicago|\n",
            "|    103|  Finance|  Boston|\n",
            "|    104|Marketing| Seattle|\n",
            "+-------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join\n",
        "\n",
        "employees_df.join(departments_df,\n",
        "                  employees_df.dept_id == departments_df.dept_id,\n",
        "                  'inner')\\\n",
        "                  .drop('epartments_df.dept_id')\\\n",
        "                  .show(truncate = False)\n",
        "\n",
        "employees_df.join(departments_df,\n",
        "                  employees_df.dept_id == departments_df.dept_id,\n",
        "                  'left')\\\n",
        "                  .drop('epartments_df.dept_id')\\\n",
        "                  .show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_QEu_V-yxAD",
        "outputId": "fc9852dc-7e7b-445c-c773-662a62c55487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|emp_id|name   |dept   |dept_id|dept_id|dept_name|location|\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|1     |Alice  |IT     |101    |101    |IT       |New York|\n",
            "|3     |Charlie|IT     |101    |101    |IT       |New York|\n",
            "|2     |Bob    |HR     |102    |102    |HR       |Chicago |\n",
            "|4     |Diana  |Finance|103    |103    |Finance  |Boston  |\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|emp_id|name   |dept   |dept_id|dept_id|dept_name|location|\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|1     |Alice  |IT     |101    |101    |IT       |New York|\n",
            "|2     |Bob    |HR     |102    |102    |HR       |Chicago |\n",
            "|4     |Diana  |Finance|103    |103    |Finance  |Boston  |\n",
            "|3     |Charlie|IT     |101    |101    |IT       |New York|\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# crossjoin\n",
        "\n",
        "employees_df.crossJoin(departments_df).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjFCtT7vzHkJ",
        "outputId": "7d245327-231a-4b21-ef59-558589ed27d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|emp_id|name   |dept   |dept_id|dept_id|dept_name|location|\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "|1     |Alice  |IT     |101    |101    |IT       |New York|\n",
            "|1     |Alice  |IT     |101    |102    |HR       |Chicago |\n",
            "|2     |Bob    |HR     |102    |101    |IT       |New York|\n",
            "|2     |Bob    |HR     |102    |102    |HR       |Chicago |\n",
            "|1     |Alice  |IT     |101    |103    |Finance  |Boston  |\n",
            "|1     |Alice  |IT     |101    |104    |Marketing|Seattle |\n",
            "|2     |Bob    |HR     |102    |103    |Finance  |Boston  |\n",
            "|2     |Bob    |HR     |102    |104    |Marketing|Seattle |\n",
            "|3     |Charlie|IT     |101    |101    |IT       |New York|\n",
            "|3     |Charlie|IT     |101    |102    |HR       |Chicago |\n",
            "|4     |Diana  |Finance|103    |101    |IT       |New York|\n",
            "|4     |Diana  |Finance|103    |102    |HR       |Chicago |\n",
            "|3     |Charlie|IT     |101    |103    |Finance  |Boston  |\n",
            "|3     |Charlie|IT     |101    |104    |Marketing|Seattle |\n",
            "|4     |Diana  |Finance|103    |103    |Finance  |Boston  |\n",
            "|4     |Diana  |Finance|103    |104    |Marketing|Seattle |\n",
            "+------+-------+-------+-------+-------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# union\n",
        "\n",
        "dataframe1_data = [\n",
        "    (1, \"Alice\", \"IT\", 5000, \"New York\"),\n",
        "    (2, \"Bob\", \"HR\", 4000, \"Chicago\"),\n",
        "    (3, \"Charlie\", \"IT\", 4500, \"New York\"),\n",
        "    (3, \"Charlie\", \"IT\", 4500, \"New York\"),\n",
        "    (4, \"Diana\", \"Finance\", 6000, \"Boston\"),\n",
        "    (5, \"Eve\", \"Marketing\", 5500, \"Seattle\")\n",
        "]\n",
        "dataframe1 = spark.createDataFrame(dataframe1_data, [\"id\", \"name\", \"department\", \"salary\", \"city\"])\n",
        "\n",
        "dataframe2_data = [\n",
        "    (3, \"Charlie\", \"IT\", 4500, \"New York\"),  # Duplicate\n",
        "    (6, \"Frank\", \"IT\", 5200, \"Austin\"),      # New\n",
        "    (7, \"Grace\", \"HR\", 4200, \"Chicago\"),     # New\n",
        "    (4, \"Diana\", \"Finance\", 6000, \"Boston\"), # Duplicate\n",
        "    (8, \"Henry\", \"Sales\", 4800, \"Miami\"),     # New\n",
        "    (3, \"Charlie\", \"IT\", 4500, \"New York\")\n",
        "]\n",
        "dataframe2 = spark.createDataFrame(dataframe2_data, [\"id\", \"name\", \"department\", \"salary\", \"city\"])"
      ],
      "metadata": {
        "id": "VP5VIMSI0B0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# union\n",
        "\n",
        "dataframe1.union(dataframe2).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dghLpF-1iNL",
        "outputId": "28f5a96e-689c-4f84-d1a3-4fe6a8906296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----------+------+--------+\n",
            "|id |name   |department|salary|city    |\n",
            "+---+-------+----------+------+--------+\n",
            "|1  |Alice  |IT        |5000  |New York|\n",
            "|2  |Bob    |HR        |4000  |Chicago |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "|5  |Eve    |Marketing |5500  |Seattle |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|6  |Frank  |IT        |5200  |Austin  |\n",
            "|7  |Grace  |HR        |4200  |Chicago |\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "|8  |Henry  |Sales     |4800  |Miami   |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "+---+-------+----------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unionall\n",
        "dataframe1.unionAll(dataframe2).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Px23AFK1sQW",
        "outputId": "312f5fd7-3558-4459-b61b-002cdd116c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----------+------+--------+\n",
            "|id |name   |department|salary|city    |\n",
            "+---+-------+----------+------+--------+\n",
            "|1  |Alice  |IT        |5000  |New York|\n",
            "|2  |Bob    |HR        |4000  |Chicago |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "|5  |Eve    |Marketing |5500  |Seattle |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|6  |Frank  |IT        |5200  |Austin  |\n",
            "|7  |Grace  |HR        |4200  |Chicago |\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "|8  |Henry  |Sales     |4800  |Miami   |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "+---+-------+----------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "- In **Spark DataFrame API**, `union()` and `unionAll()` are identical - both keep duplicates\n",
        "- In **Spark SQL**, `UNION` removes duplicates while `UNION ALL` keeps duplicates\n",
        "- This is a known inconsistency between DataFrame API and SQL in Spark"
      ],
      "metadata": {
        "id": "RX-VUpvh14B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unionByName\n",
        "\n",
        "dataframe1_reordered = dataframe1.select('name','department','id')\n",
        "dataframe2_reordered = dataframe1.select('id','name','department')\n",
        "\n",
        "dataframe1_reordered.unionByName(dataframe2_reordered).show(truncate= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtjk-CRa10H1",
        "outputId": "c3371eb7-ebde-41bd-cb60-57c391c22569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---+\n",
            "|name   |department|id |\n",
            "+-------+----------+---+\n",
            "|Alice  |IT        |1  |\n",
            "|Bob    |HR        |2  |\n",
            "|Charlie|IT        |3  |\n",
            "|Charlie|IT        |3  |\n",
            "|Diana  |Finance   |4  |\n",
            "|Eve    |Marketing |5  |\n",
            "|Alice  |IT        |1  |\n",
            "|Bob    |HR        |2  |\n",
            "|Charlie|IT        |3  |\n",
            "|Charlie|IT        |3  |\n",
            "|Diana  |Finance   |4  |\n",
            "|Eve    |Marketing |5  |\n",
            "+-------+----------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note\n",
        "* `union()` = \"Strict mode\" - schemas must be identical\n",
        "* `unionByName()` = \"Flexible mode\" - schemas can differ\n",
        "* `unionByName()` with allowMissingColumns=True = \"Forgiving mode\" - handles schema evolution\n",
        "\n",
        "Use unionByName() when working with data from multiple sources or when schemas might change over time!"
      ],
      "metadata": {
        "id": "yvKyDHNl4Hd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# intersect\n",
        "\n",
        "dataframe1.intersect(dataframe2).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciWnHg_p3x1h",
        "outputId": "bd9b4072-20d0-43fe-dbaa-402d9715c62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----------+------+--------+\n",
            "|id |name   |department|salary|city    |\n",
            "+---+-------+----------+------+--------+\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "+---+-------+----------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# intersectAll\n",
        "\n",
        "dataframe1.intersectAll(dataframe2).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uF9tj084fuv",
        "outputId": "d60f6fdd-762d-47ea-9d7a-9c1c9197cf23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+----------+------+--------+\n",
            "|id |name   |department|salary|city    |\n",
            "+---+-------+----------+------+--------+\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|3  |Charlie|IT        |4500  |New York|\n",
            "|4  |Diana  |Finance   |6000  |Boston  |\n",
            "+---+-------+----------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intersect vs IntersectAll\n",
        "\n",
        "##### `intersect()`\n",
        "- **Shows only unique common records**\n",
        "- Removes all duplicates  \n",
        "- **Answers**: \"Which records are common?\"\n",
        "\n",
        "##### `intersectAll()`\n",
        "- **Shows all common records with duplicates**\n",
        "- Keeps duplicate counts\n",
        "- **Answers**: \"How many times are records common?\"\n",
        "\n",
        "##### Simple Examples:\n",
        "\n",
        "##### Example 1: `[A, A, B] ‚à© [A, B, B]`\n",
        "- **`intersect()`** = `[A, B]` (only unique)\n",
        "- **`intersectAll()`** = `[A, B]` (min counts: A=1, B=1)\n",
        "\n",
        "##### Example 2: `[A, A, B] ‚à© [A, A, B]`  \n",
        "- **`intersect()`** = `[A, B]`\n",
        "- **`intersectAll()`** = `[A, A, B]` (min counts: A=2, B=1)\n",
        "\n",
        "##### When to Use:\n",
        "- **Use `intersect()`** for checking existence\n",
        "- **Use `intersectAll()`** for counting occurrences"
      ],
      "metadata": {
        "id": "Ewf0iNAB6YAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exceptAll\n",
        "\n",
        "dataframe1.exceptAll(dataframe2).show(truncate = False)\n",
        "dataframe2.exceptAll(dataframe1).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hC3h3VW4lp4",
        "outputId": "f477395a-f884-4070-dae1-d8f72af9c34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+--------+\n",
            "|id |name |department|salary|city    |\n",
            "+---+-----+----------+------+--------+\n",
            "|1  |Alice|IT        |5000  |New York|\n",
            "|2  |Bob  |HR        |4000  |Chicago |\n",
            "|5  |Eve  |Marketing |5500  |Seattle |\n",
            "+---+-----+----------+------+--------+\n",
            "\n",
            "+---+-----+----------+------+-------+\n",
            "|id |name |department|salary|city   |\n",
            "+---+-----+----------+------+-------+\n",
            "|6  |Frank|IT        |5200  |Austin |\n",
            "|7  |Grace|HR        |4200  |Chicago|\n",
            "|8  |Henry|Sales     |4800  |Miami  |\n",
            "+---+-----+----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtract\n",
        "\n",
        "dataframe1.subtract(dataframe2).show(truncate = False)\n",
        "dataframe2.subtract(dataframe1).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu840xzM67nr",
        "outputId": "9a8e544f-0b58-4a20-f059-01e86082c37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+--------+\n",
            "|id |name |department|salary|city    |\n",
            "+---+-----+----------+------+--------+\n",
            "|5  |Eve  |Marketing |5500  |Seattle |\n",
            "|1  |Alice|IT        |5000  |New York|\n",
            "|2  |Bob  |HR        |4000  |Chicago |\n",
            "+---+-----+----------+------+--------+\n",
            "\n",
            "+---+-----+----------+------+-------+\n",
            "|id |name |department|salary|city   |\n",
            "+---+-----+----------+------+-------+\n",
            "|6  |Frank|IT        |5200  |Austin |\n",
            "|7  |Grace|HR        |4200  |Chicago|\n",
            "|8  |Henry|Sales     |4800  |Miami  |\n",
            "+---+-----+----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : ExceptAll and subtract are functionally the same thing"
      ],
      "metadata": {
        "id": "VdDYNxaw7YdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "dataframe.sample(fraction = 0.1).show(truncate = False)\n",
        "dataframe.sample(fraction = 0.1, seed = 50).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsGdZ7Gk7PaU",
        "outputId": "b30293ca-314d-476e-9246-445d3b05e08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+-----------+-------+---+---------+----------+-------+\n",
            "|employee_id|name|department |salary |age|is_active|hire_date |city   |\n",
            "+-----------+----+-----------+-------+---+---------+----------+-------+\n",
            "|7          |NULL|Engineering|68000.6|27 |false    |2022-02-14|Seattle|\n",
            "|15         |Mona|NULL       |52000.5|26 |true     |2022-08-09|Chicago|\n",
            "+-----------+----+-----------+-------+---+---------+----------+-------+\n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|8          |Grace  |Marketing  |NULL    |33 |true     |2019-09-08|Austin  |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sampleBy : stratified sampling by a specifed column\n",
        "\n",
        "dataframe.sampleBy(col = 'department',fractions={'Engineering': 0.8, 'Marketing': 0.1}, seed = 50).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wjAB4JG7tWq",
        "outputId": "a3036553-08a0-4678-849d-0058f12aed90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|1          |Alice  |Engineering|75000.5 |28 |true     |2020-01-15|New York|\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|7          |NULL   |Engineering|68000.6 |27 |false    |2022-02-14|Seattle |\n",
            "|8          |Grace  |Marketing  |NULL    |33 |true     |2019-09-08|Austin  |\n",
            "|11         |       |Engineering|0.0     |0  |false    |2023-01-01|        |\n",
            "|14         |Leo    |Engineering|95000.0 |45 |false    |2016-04-18|New York|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomSplit : randomly splits the dataframe based on a weight returns a list of dataframes\n",
        "\n",
        "splits = dataframe.randomSplit(weights=[0.2,0.6,0.2])\n",
        "\n",
        "print(splits,'\\n')\n",
        "\n",
        "print([type(x) for x in splits],'\\n')\n",
        "\n",
        "splits[0].show()\n",
        "\n",
        "print([x.count() for x in splits])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLMp8fdM8gWO",
        "outputId": "fc75ba23-51d2-499d-87ff-a97770b42b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string], DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string], DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]] \n",
            "\n",
            "[<class 'pyspark.sql.dataframe.DataFrame'>, <class 'pyspark.sql.dataframe.DataFrame'>, <class 'pyspark.sql.dataframe.DataFrame'>] \n",
            "\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|   name| department|  salary|age|is_active| hire_date|    city|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|          3|Charlie|Engineering|82000.25| 35|     true|2018-07-10|New York|\n",
            "|          4|  Diana|      Sales| 58000.0| 29|     true|2021-05-05| Chicago|\n",
            "|         15|   Mona|       NULL| 52000.5| 26|     true|2022-08-09| Chicago|\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n",
            "[3, 9, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spark Sampling Methods Comparison\n",
        "\n",
        "| Feature | `sample()` | `sampleBy()` | `randomSplit()` |\n",
        "|---------|------------|--------------|-----------------|\n",
        "| **Purpose** | Random sampling from entire dataset | Stratified sampling by groups | Split dataset into multiple parts |\n",
        "| **Sampling Type** | Simple random sampling | Stratified random sampling | Multiple random splits |\n",
        "| **Control Level** | Dataset level | Group/column level | Dataset level |\n",
        "| **Output** | Single DataFrame | Single DataFrame | List of DataFrames |\n",
        "| **Fractions Parameter** | Single fraction for all data | Dict of fractions per group | List of weights for splits |\n",
        "| **Usage** | `df.sample(0.3)` | `df.sampleBy(\"dept\", {'DataEnginering':0.1, 'Analytics':0.2})` | `df.randomSplit([0.6, 0.4])` |\n",
        "| **Group Proportionality** | ‚ùå Not maintained | ‚úÖ Maintained | ‚ùå Not maintained |\n",
        "| **Use Case** | Quick random subset | Representative samples by category | Train/validation/test splits |"
      ],
      "metadata": {
        "id": "JcT3-mtpAgGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# repartition\n",
        "\n",
        "from pyspark.sql.functions import spark_partition_id\n",
        "\n",
        "dataframe.repartition(3)\\\n",
        "         .select('*', spark_partition_id().alias('spark_partition_id')).show(truncate=False)  ## with numPartitions\n",
        "\n",
        "dataframe.repartition('department')\\\n",
        "         .select('*', spark_partition_id().alias('spark_partition_id')).show(truncate = False)  ## with partitionColumns\n",
        "\n",
        "dataframe.repartition(3,'department')\\\n",
        "         .select('*', spark_partition_id().alias('spark_partition_id')).show(truncate = False)  ## with numPartitions, partitionColumns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_TepGh-8fX",
        "outputId": "879d072f-ed09-4dca-8a0a-baa76320c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |spark_partition_id|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |0                 |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |0                 |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |0                 |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |0                 |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |0                 |\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |1                 |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |1                 |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |1                 |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |1                 |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |1                 |\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |2                 |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|2                 |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |2                 |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |2                 |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |2                 |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |spark_partition_id|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |0                 |\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |0                 |\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |0                 |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |0                 |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |0                 |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |0                 |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|0                 |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |0                 |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |0                 |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |0                 |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |0                 |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |0                 |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |0                 |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |0                 |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |0                 |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |spark_partition_id|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|0                 |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |0                 |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |0                 |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |0                 |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |0                 |\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |1                 |\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |1                 |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |1                 |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |1                 |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |1                 |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |1                 |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |1                 |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |2                 |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |2                 |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |2                 |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### repartition() Methods\n",
        "---\n",
        "| Aspect | `repartition(N)` | `repartition(\"col\")` | `repartition(N, \"col\")` |\n",
        "|--------|------------------|---------------------|------------------------|\n",
        "| **Conceptual Purpose** | Balance data across N partitions | Group same column values together | Group values + control partition count |\n",
        "| **Data Distribution** | Random shuffle | Hash-based by column value | Hash-based by column value |\n",
        "| **Partition Count** | Exactly N partitions | Default (200) partitions | Exactly N partitions |\n",
        "| **Data Locality** | No guarantee - random | Same values in same partition | Same values in same partition |\n",
        "| **Shuffle Operation** | Full shuffle (expensive) | Full shuffle (expensive) | Full shuffle (expensive) |\n",
        "| **Performance Impact** | High (shuffles all data) | High (shuffles all data) | High (shuffles all data) |\n",
        "---\n",
        "#### Technical Details\n",
        "---\n",
        "\n",
        "| Aspect | `repartition(N)` | `repartition(\"col\")` | `repartition(N, \"col\")` |\n",
        "|--------|------------------|---------------------|------------------------|\n",
        "| **Internal Logic** | `HashPartitioner(random)` | `HashPartitioner(col.hash)` | `HashPartitioner(col.hash % N)` |\n",
        "| **Data Skew Risk** | Low (random distribution) | High (if column values uneven) | High (if N < distinct values) |\n",
        "| **Query Optimization** | Limited benefit | Enables partition pruning | Enables partition pruning |\n",
        "| **Memory Usage** | Balanced across executors | Depends on value distribution | Depends on value distribution |\n",
        "| **Default N** | User-specified | 200 (spark.sql.shuffle.partitions) | User-specified |\n",
        "---\n",
        "#### Use Case Scenarios\n",
        "---\n",
        "\n",
        "| Aspect | `repartition(N)` | `repartition(\"col\")` | `repartition(N, \"col\")` |\n",
        "|--------|------------------|---------------------|------------------------|\n",
        "| **Best For** | General load balancing | Filtering/joining on specific column | Optimized storage + query performance |\n",
        "| **Example Scenario** | Before expensive operations | Before `filter(col=value)` or `join(on=col)` | Before writing partitioned data to disk |\n",
        "| **When to Avoid** | Small datasets, frequent operations | High-cardinality columns, small datasets | When N < distinct values causing skew |\n",
        "---\n",
        "#### Performance Characteristics\n",
        "---\n",
        "\n",
        "| Aspect | `repartition(N)` | `repartition(\"col\")` | `repartition(N, \"col\")` |\n",
        "|--------|------------------|---------------------|------------------------|\n",
        "| **Shuffle Cost** | High | High | High |\n",
        "| **Subsequent Operation Speed** | Moderate improvement | Significant improvement for column-based ops | Best for targeted operations |\n",
        "| **Storage Efficiency** | Poor | Good for partitioned storage | Excellent for partitioned storage |\n",
        "| **Risk of Data Skew** | Low | Medium | High if poor N choice |"
      ],
      "metadata": {
        "id": "mug2A7agFV1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#repartitionByRange\n",
        "\n",
        "dataframe.repartitionByRange(3,'department')\\\n",
        "         .select('*', spark_partition_id().alias('spark_partition_id')).show(truncate = False)  ## with numPartitions, partitionColumns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vls3mZMCp9r",
        "outputId": "479ead88-2a1e-409e-b448-e3de3e720d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |spark_partition_id|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |0                 |\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |0                 |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |0                 |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |0                 |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |0                 |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |0                 |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |0                 |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|1                 |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |1                 |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |1                 |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |1                 |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |1                 |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |2                 |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |2                 |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |2                 |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `repartition()` vs `repartitionByRange()`\n",
        "\n",
        "| Aspect | `repartition()` | `repartitionByRange()` |\n",
        "|--------|-----------------|------------------------|\n",
        "| **Partitioning Method** | Hash partitioning | Range partitioning |\n",
        "| **Data Distribution** | Based on hash codes of column values | Based on actual value ranges |\n",
        "| **Ordering** | No ordering within partitions | Values are sorted within range boundaries |\n",
        "| **Use Case** | General data distribution, joins, aggregations | Sorting, window operations, range queries |\n",
        "| **Performance** | Faster for equal distribution | Slower (requires sampling and sorting) |"
      ],
      "metadata": {
        "id": "Iq1l4fo9JKTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coalesce\n",
        "\n",
        "dataframe.coalesce(3)\\\n",
        "         .select('*', spark_partition_id().alias('spark_partition_id')).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91ftNov1I9MJ",
        "outputId": "f9718768-ec7c-465d-ad96-f64afdc3d329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |spark_partition_id|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |0                 |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|0                 |\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |0                 |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |0                 |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |0                 |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |0                 |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |0                 |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |1                 |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |1                 |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |1                 |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |1                 |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |1                 |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |1                 |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |1                 |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |1                 |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### repartition() vs coalesce()\n",
        "\n",
        "#### Core Difference\n",
        "- **`repartition()`**: Full shuffle, increases/decreases partitions, perfect data balance\n",
        "- **`coalesce()`**: No shuffle, decreases partitions only, minimal data movement\n",
        "\n",
        "#### When repartition() is Essential (Not Optional)\n",
        "\n",
        "#### 1. **Preventing Data Skew**\n",
        "- Critical for joins on skewed keys (90% users in one country)\n",
        "- Avoids single executor processing majority of data\n",
        "- Essential for stable join operations\n",
        "\n",
        "#### 2. **Memory Management & OOM Prevention**\n",
        "- Large partitions can crash executors with OutOfMemory errors\n",
        "- Ensures predictable memory usage across cluster\n",
        "- Required for production job stability\n",
        "\n",
        "#### 3. **Optimizing Cluster Utilization**\n",
        "- Enables maximum parallel processing\n",
        "- Prevents underutilized CPU cores\n",
        "- Essential for cost-effective cloud computing\n",
        "\n",
        "#### 4. **Performance-Critical Operations**\n",
        "- Before complex aggregations and window functions\n",
        "- For time-sensitive production pipelines\n",
        "- When job completion SLAs must be met\n",
        "\n",
        "#### When to Use Each\n",
        "\n",
        "| Scenario | Use | Reason |\n",
        "|----------|-----|--------|\n",
        "| **Increasing partitions** | `repartition()` | `coalesce()` cannot increase |\n",
        "| **Data skew present** | `repartition()` | Essential for job stability |\n",
        "| **Memory concerns** | `repartition()` | Prevents OOM errors |\n",
        "| **Before expensive joins** | `repartition()` | Ensures balanced execution |\n",
        "| **Reducing partitions after filter** | `coalesce()` | No shuffle needed |\n",
        "| **Writing to storage** | `coalesce()` | Avoids small files efficiently |\n",
        "| **Simple partition reduction** | `coalesce()` | Fast, minimal overhead |\n",
        "\n",
        "#### Performance & Impact\n",
        "\n",
        "| Aspect | `repartition()` | `coalesce()` |\n",
        "|--------|-----------------|--------------|\n",
        "| **Execution Speed** | Slow (shuffle) | Fast (no shuffle) |\n",
        "| **Network I/O** | High | None/Low |\n",
        "| **Data Balance** | Perfect | Partial |\n",
        "| **Job Reliability** | High | Risk of skew/OOM |\n",
        "| **Memory Safety** | Excellent | Potentially risky |\n",
        "\n",
        "#### Critical Decision Points\n",
        "\n",
        "#### Use `repartition()` when:\n",
        "- Data distribution is uneven (skew)\n",
        "- Memory errors occur in current job\n",
        "- Joining on high-cardinality columns\n",
        "- Maximum parallelism required\n",
        "- Production job stability is critical\n",
        "\n",
        "#### Use `coalesce()` when:\n",
        "- Simply reducing partition count\n",
        "- After filtering/aggregation operations\n",
        "- Writing output files\n",
        "- Performance is primary concern\n",
        "- Data is already well-distributed\n",
        "\n",
        "#### Key Insight\n",
        "**`repartition()` is not just an optimization - it's essential for reliable Spark job execution with real-world data. While `coalesce()` is more efficient, `repartition()` ensures your jobs don't fail due to skew or memory issues.**\n",
        "\n",
        "**Choose: `coalesce()` for speed, `repartition()` for reliability**"
      ],
      "metadata": {
        "id": "7X_VJi0jQQus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cache\n",
        "\n",
        "dataframe.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbPme7VdOIX-",
        "outputId": "1df47414-6435-4069-e208-84b55d02ee42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.show(truncate= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl4L_RMXWNma",
        "outputId": "2015afc8-60fd-48fa-dad0-cee1f5a6e8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is cache()?\n",
        "\n",
        "> cache() is a method that persists a DataFrame in memory across Spark executors for faster repeated access.\n",
        "\n",
        "Key Characteristics of `cache`\n",
        "\n",
        "* Storage Level\tMEMORY_AND_DISK (default)\n",
        "* Persistence\tSurvives Spark operations, not Spark restarts\n",
        "* Lazy Evaluation\tCache happens on first action, not immediately\n",
        "* Memory Management\tLRU eviction when memory is full\n",
        "* When to Use cache()\n",
        "\n",
        "‚úÖ Use cache() when:\n",
        "\n",
        "* Multiple actions on same DataFrame\n",
        "* Iterative algorithms (ML training)\n",
        "* Repeated transformations on same base data\n",
        "* Interactive analysis and debugging\n",
        "* Complex DAGs with reused DataFrames\n",
        "\n",
        "‚ùå Avoid cache() when:\n",
        "\n",
        "* Single use DataFrames\n",
        "* Very large datasets that don't fit in memory\n",
        "* Simple linear workflows\n",
        "* Memory-constrained environments"
      ],
      "metadata": {
        "id": "tDnFbS2OWlcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# persist\n",
        "\n",
        "dataframe.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZGOjQgOWRCx",
        "outputId": "2a985bde-0b18-4d2c-a2bb-fccdd507cfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCoJzuGyXPRh",
        "outputId": "84a70d72-12ca-4689-f8f0-23217dd0ed18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unpersist\n",
        "\n",
        "dataframe.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMDkR7vfXSJp",
        "outputId": "802b86d2-ce00-4923-89c3-cac9f5a06670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import StorageLevel\n",
        "dataframe.persist(StorageLevel.MEMORY_AND_DISK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3UCZujqXWOK",
        "outputId": "43211e6a-7e01-4eda-fe9c-5a3eb30e0fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg3QeCtggj-f",
        "outputId": "cc1465ec-1027-432d-cf01-7c2b59ddaff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`persist()` is a method that allows you to explicitly specify the storage level for persisting a DataFrame, giving you fine-grained control over how data is cached."
      ],
      "metadata": {
        "id": "pU8MugVZg2Sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##### DataFrame.cache() vs persist()\n",
        "\n",
        "| Aspect | `cache()` | `persist()` | Notes |\n",
        "|--------|-----------|-------------|-------|\n",
        "| **Storage Level** | Fixed: `MEMORY_AND_DISK` | Customizable: Any StorageLevel | |\n",
        "| **Flexibility** | Limited | High | |\n",
        "| **Use Case** | Simple caching | Advanced memory management | |\n",
        "| **Syntax** | `df.cache()` | `df.persist()` or `df.persist(StorageLevel.X)` | |\n",
        "| **Default Behavior** | MEMORY_AND_DISK | MEMORY_AND_DISK (when no parameter) | |\n",
        "| **Memory Control** | Basic | Granular | |\n",
        "| **Performance Tuning** | Limited | Extensive | |\n",
        "| **Unpersist Counterpart** | ‚úÖ `df.unpersist()` | ‚úÖ `df.unpersist()` | **Both use same unpersist()** |\n",
        "| **Cleanup Method** | Same unpersist() | Same unpersist() | No separate \"uncache()\" |\n",
        "---\n",
        "##### Important Clarification\n",
        "\n",
        "**Both `cache()` and `persist()` use the SAME `unpersist()` method** - there is no separate `uncache()` method.\n",
        "---\n",
        "##### Usage Pattern:\n",
        "```python\n",
        "# For cache()\n",
        "df.cache()\n",
        "df.unpersist()  # Removes from cache\n",
        "---\n",
        "# For persist()  \n",
        "df.persist(StorageLevel.MEMORY_ONLY)\n",
        "df.unpersist()  # Removes from persistence\n",
        "\n",
        "# Both work exactly the same way!"
      ],
      "metadata": {
        "id": "bMWrtXwoh0nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")\n",
        "\n",
        "dataframe.checkpoint(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfP2RAcIhw_M",
        "outputId": "80540cc4-73e8-40cd-b249-a09d1ced2fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# localCheckpoints\n",
        "\n",
        "dataframe.localCheckpoint(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWpngYXnlwug",
        "outputId": "f30e9b82-f004-4ecf-af9b-54f41e7dfa89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.unpersist() ## this cleans up the local checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LWLRRH0mmVT",
        "outputId": "a386dd6f-6bac-4932-c799-160087de378a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[employee_id: int, name: string, department: string, salary: double, age: int, is_active: boolean, hire_date: date, city: string]"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import atexit # this cleans up the path check points\n",
        "\n",
        "# Register cleanup function\n",
        "def cleanup_checkpoints():\n",
        "    checkpoint_dir = \"/tmp/checkpoints\"\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        shutil.rmtree(checkpoint_dir)\n",
        "        print(\"Checkpoints cleaned up\")\n",
        "\n",
        "atexit.register(cleanup_checkpoints)  # Run on exit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Va7Qjf7amt7i",
        "outputId": "d5b12117-65ec-437b-9416-3f3502f19bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.cleanup_checkpoints()>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>cleanup_checkpoints</b><br/>def cleanup_checkpoints()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/tmp/ipython-input-1985659680.py</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* What is checkpoint()? *\n",
        "---\n",
        "> checkpoint() is a method that saves a DataFrame to reliable storage (like HDFS) and breaks the lineage graph, providing fault tolerance and preventing expensive recomputations in case of failure occurs.\n",
        "---\n",
        "‚úÖ Use checkpoint() when:\n",
        "\n",
        "* Long, complex transformation chains\n",
        "* Iterative algorithms (ML, graph processing)\n",
        "* Memory-intensive operations\n",
        "* Debugging complex pipelines\n",
        "* Production reliability requirements\n",
        "* Streaming applications\n",
        "\n",
        "‚ùå Avoid checkpoint() when:\n",
        "\n",
        "* Simple, fast transformations\n",
        "* Limited storage available\n",
        "* Development/testing environments\n",
        "* Linear pipelines with no iterations\n",
        "\n",
        "`checkpoint` vs `localCheckpoint`\n",
        "\n",
        "* checkpoint(): Saves to reliable storage (HDFS, S3), survives driver/executor failures\n",
        "* localCheckpoint(): Saves to executor local storage, faster but less reliable"
      ],
      "metadata": {
        "id": "QnqN_NrKkA4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# corr\n",
        "\n",
        "# returns a scaler output\n",
        "\n",
        "dataframe.corr('salary','age')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYynyl69jeRK",
        "outputId": "f8150270-3da7-4666-adab-800ccf74113a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.854241841921367"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cov\n",
        "\n",
        "# returns a scaler output\n",
        "\n",
        "dataframe.cov('salary','age')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPbGNbtRnMcT",
        "outputId": "00eb0bcd-9ff5-49d9-dc89-1e1ad7691166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4672573.763"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freqItems\n",
        "\n",
        "dataframe.freqItems(['department']).show(truncate = False)\n",
        "dataframe.freqItems(['department'], support=0.5).show(truncate = False) # with a threshold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb-JSUsPoUjk",
        "outputId": "ebc41fe5-9a21-47c5-b1f9-b6660dde7387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------+\n",
            "|department_freqItems                     |\n",
            "+-----------------------------------------+\n",
            "|[HR, Engineering, Marketing, NULL, Sales]|\n",
            "+-----------------------------------------+\n",
            "\n",
            "+--------------------+\n",
            "|department_freqItems|\n",
            "+--------------------+\n",
            "|[Engineering, NULL] |\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> freqItems() Threshold Explained\n",
        "Default Threshold\n",
        "\n",
        "* By default, freqItems() uses support = 0.01 (1%)\n",
        "\n",
        "This means:\n",
        "* Any value that appears in ‚â•1% of the rows is included\n",
        "* Values appearing in <1% of rows are excluded"
      ],
      "metadata": {
        "id": "9pQ7DDnWrWYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stat\n",
        "# accessor of the dataframe\n",
        "\n",
        "dataframe.stat.corr('age','salary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5Sgxhlzsa0D",
        "outputId": "c6e17bb5-ab39-4191-d858-1594b0bfdb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.854241841921367"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.stat.cov('age','salary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uodKgPbJxvPQ",
        "outputId": "0b494363-88ea-4d27-d807-7e9c62a3cb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4672573.763"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.stat.crosstab('department','city').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvL56_wtyIvc",
        "outputId": "40dfe0c2-c42d-4b3b-8430-5214cfc6772a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "|department_city|   |Atlanta|Austin|Boston|Chicago|Denver|Miami|New York|Portland|San Francisco|Seattle|null|\n",
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "|          Sales|  0|      0|     0|     0|      1|     1|    1|       0|       0|            0|      0|   0|\n",
            "|    Engineering|  1|      0|     0|     0|      0|     0|    0|       3|       0|            0|      1|   0|\n",
            "|             HR|  0|      0|     0|     1|      0|     0|    0|       0|       1|            0|      0|   0|\n",
            "|      Marketing|  0|      1|     1|     0|      0|     0|    0|       0|       0|            1|      0|   0|\n",
            "|           null|  0|      0|     0|     0|      1|     0|    0|       0|       0|            0|      0|   1|\n",
            "+---------------+---+-------+------+------+-------+------+-----+--------+--------+-------------+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.stat.freqItems(['department'], support=0.4).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lWLLQNNyRys",
        "outputId": "c80c7c2e-c9c1-48ea-e91e-6c93882d91e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|department_freqItems|\n",
            "+--------------------+\n",
            "|[Engineering, NULL] |\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.stat.sampleBy('department', {'Engineering':0.2, 'Marketing':0.3}, seed = 50).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM1_G8X2ydaW",
        "outputId": "77671c74-8509-428a-b837-4619f2b763bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|employee_id|name   |department |salary  |age|is_active|hire_date |city    |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "|3          |Charlie|Engineering|82000.25|35 |true     |2018-07-10|New York|\n",
            "|8          |Grace  |Marketing  |NULL    |33 |true     |2019-09-08|Austin  |\n",
            "+-----------+-------+-----------+--------+---+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toPandas\n",
        "\n",
        "print(type(dataframe.toPandas()),'\\n')\n",
        "dataframe.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "HQ6oXtj3zXXY",
        "outputId": "cc9f398b-d7c0-41fd-9305-2fb1860621cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    employee_id     name   department      salary   age is_active   hire_date  \\\n",
              "0             1    Alice  Engineering    75000.50  28.0      True  2020-01-15   \n",
              "1             2      Bob    Marketing    65000.75  32.0     False  2019-03-20   \n",
              "2             3  Charlie  Engineering    82000.25  35.0      True  2018-07-10   \n",
              "3             4    Diana        Sales    58000.00  29.0      True  2021-05-05   \n",
              "4             5      Eve           HR    62000.80  31.0     False  2020-11-30   \n",
              "5             6    Frank         None    71000.40  40.0      True  2017-08-25   \n",
              "6             7     None  Engineering    68000.60  27.0     False  2022-02-14   \n",
              "7             8    Grace    Marketing         NaN  33.0      True  2019-09-08   \n",
              "8             9    Henry        Sales    59000.90   NaN     False  2021-12-01   \n",
              "9            10      Ivy           HR    63000.30  36.0      None        None   \n",
              "10           11           Engineering        0.00   0.0     False  2023-01-01   \n",
              "11           12     Jack        Sales  1000000.99  99.0      True  2015-12-31   \n",
              "12           13    Karen    Marketing    45000.00  22.0      True  2023-06-15   \n",
              "13           14      Leo  Engineering    95000.00  45.0     False  2016-04-18   \n",
              "14           15     Mona         None    52000.50  26.0      True  2022-08-09   \n",
              "\n",
              "             city  \n",
              "0        New York  \n",
              "1   San Francisco  \n",
              "2        New York  \n",
              "3         Chicago  \n",
              "4          Boston  \n",
              "5            None  \n",
              "6         Seattle  \n",
              "7          Austin  \n",
              "8          Denver  \n",
              "9        Portland  \n",
              "10                 \n",
              "11          Miami  \n",
              "12        Atlanta  \n",
              "13       New York  \n",
              "14        Chicago  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6423ace-34cd-41ac-b73b-bb6a045974ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employee_id</th>\n",
              "      <th>name</th>\n",
              "      <th>department</th>\n",
              "      <th>salary</th>\n",
              "      <th>age</th>\n",
              "      <th>is_active</th>\n",
              "      <th>hire_date</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Alice</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>75000.50</td>\n",
              "      <td>28.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Bob</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>65000.75</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2019-03-20</td>\n",
              "      <td>San Francisco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Charlie</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>82000.25</td>\n",
              "      <td>35.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-07-10</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Diana</td>\n",
              "      <td>Sales</td>\n",
              "      <td>58000.00</td>\n",
              "      <td>29.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2021-05-05</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Eve</td>\n",
              "      <td>HR</td>\n",
              "      <td>62000.80</td>\n",
              "      <td>31.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-11-30</td>\n",
              "      <td>Boston</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Frank</td>\n",
              "      <td>None</td>\n",
              "      <td>71000.40</td>\n",
              "      <td>40.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2017-08-25</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>68000.60</td>\n",
              "      <td>27.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-02-14</td>\n",
              "      <td>Seattle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Grace</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2019-09-08</td>\n",
              "      <td>Austin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Henry</td>\n",
              "      <td>Sales</td>\n",
              "      <td>59000.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Ivy</td>\n",
              "      <td>HR</td>\n",
              "      <td>63000.30</td>\n",
              "      <td>36.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Portland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td></td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Jack</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1000000.99</td>\n",
              "      <td>99.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>Miami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Karen</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>45000.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2023-06-15</td>\n",
              "      <td>Atlanta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>Leo</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>95000.00</td>\n",
              "      <td>45.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2016-04-18</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Mona</td>\n",
              "      <td>None</td>\n",
              "      <td>52000.50</td>\n",
              "      <td>26.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2022-08-09</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6423ace-34cd-41ac-b73b-bb6a045974ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6423ace-34cd-41ac-b73b-bb6a045974ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6423ace-34cd-41ac-b73b-bb6a045974ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9bed82c1-5711-406f-bcf6-09d42b2120b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bed82c1-5711-406f-bcf6-09d42b2120b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9bed82c1-5711-406f-bcf6-09d42b2120b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"employee_id\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"\",\n          \"Karen\",\n          \"Alice\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Marketing\",\n          \"HR\",\n          \"Engineering\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251840.52466672033,\n        \"min\": 0.0,\n        \"max\": 1000000.99,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          45000.0,\n          75000.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.252149212581916,\n        \"min\": 0.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          22.0,\n          28.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_active\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hire_date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-12-31 00:00:00\",\n        \"max\": \"2023-06-15 00:00:00\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2023-01-01\",\n          \"2023-06-15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Austin\",\n          \"New York\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### dataframe.toPandas()\n",
        "\n",
        "#### What It Is\n",
        "- Converts **Spark DataFrame** (distributed, cluster) ‚Üí **Pandas DataFrame** (local, single machine)\n",
        "- Moves **all data** from Spark executors to driver node memory\n",
        "\n",
        "#### When to Use It\n",
        "\n",
        "#### ‚úÖ Appropriate Use Cases\n",
        "1. **Visualization** - Plotting libraries (matplotlib, seaborn) need local data\n",
        "2. **Small Results** - After aggregations when output is small\n",
        "3. **Python Ecosystem** - Integration with scikit-learn, statsmodels, etc.\n",
        "4. **Debugging** - Familiar pandas interface for data inspection\n",
        "5. **Prototyping** - Quick iteration on data samples\n",
        "\n",
        "#### ‚ùå When to Avoid\n",
        "1. **Large Datasets** - Risk of out-of-memory errors\n",
        "2. **Production Pipelines** - Loses Spark's distributed advantages\n",
        "3. **Big Data Processing** - Single machine can't handle terabytes\n",
        "\n",
        "#### Key Trade-offs\n",
        "\n",
        "| Aspect | Spark DataFrame | Pandas DataFrame |\n",
        "|--------|-----------------|------------------|\n",
        "| **Processing** | Distributed | Single machine |\n",
        "| **Data Size** | Terabytes+ | Limited by RAM |\n",
        "| **Operations** | Parallel | Single-threaded |\n",
        "| **Resources** | Cluster | Local |\n",
        "\n",
        "#### Strategic Usage Pattern\n",
        "**Process in Spark ‚Üí Convert small results to Pandas ‚Üí Use Python ecosystem**\n",
        "\n",
        "#### Bottom Line\n",
        "`toPandas()` is a **bridge between distributed computing and Python data science**, but should be used selectively due to memory constraints."
      ],
      "metadata": {
        "id": "HIi59U0p1Q2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas_api()\n",
        "print(type(dataframe.pandas_api()),'\\n')\n",
        "\n",
        "dataframe.pandas_api()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Aw1yiLXnzgcU",
        "outputId": "11b65433-fa1b-46cd-df72-4e846373b9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.pandas.frame.DataFrame'> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    employee_id     name   department      salary   age is_active   hire_date           city\n",
              "0             1    Alice  Engineering    75000.50  28.0      True  2020-01-15       New York\n",
              "1             2      Bob    Marketing    65000.75  32.0     False  2019-03-20  San Francisco\n",
              "2             3  Charlie  Engineering    82000.25  35.0      True  2018-07-10       New York\n",
              "3             4    Diana        Sales    58000.00  29.0      True  2021-05-05        Chicago\n",
              "4             5      Eve           HR    62000.80  31.0     False  2020-11-30         Boston\n",
              "5             6    Frank         None    71000.40  40.0      True  2017-08-25           None\n",
              "6             7     None  Engineering    68000.60  27.0     False  2022-02-14        Seattle\n",
              "7             8    Grace    Marketing         NaN  33.0      True  2019-09-08         Austin\n",
              "8             9    Henry        Sales    59000.90   NaN     False  2021-12-01         Denver\n",
              "9            10      Ivy           HR    63000.30  36.0      None        None       Portland\n",
              "10           11           Engineering        0.00   0.0     False  2023-01-01               \n",
              "11           12     Jack        Sales  1000000.99  99.0      True  2015-12-31          Miami\n",
              "12           13    Karen    Marketing    45000.00  22.0      True  2023-06-15        Atlanta\n",
              "13           14      Leo  Engineering    95000.00  45.0     False  2016-04-18       New York\n",
              "14           15     Mona         None    52000.50  26.0      True  2022-08-09        Chicago"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employee_id</th>\n",
              "      <th>name</th>\n",
              "      <th>department</th>\n",
              "      <th>salary</th>\n",
              "      <th>age</th>\n",
              "      <th>is_active</th>\n",
              "      <th>hire_date</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Alice</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>75000.50</td>\n",
              "      <td>28.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Bob</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>65000.75</td>\n",
              "      <td>32.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2019-03-20</td>\n",
              "      <td>San Francisco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Charlie</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>82000.25</td>\n",
              "      <td>35.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-07-10</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Diana</td>\n",
              "      <td>Sales</td>\n",
              "      <td>58000.00</td>\n",
              "      <td>29.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2021-05-05</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Eve</td>\n",
              "      <td>HR</td>\n",
              "      <td>62000.80</td>\n",
              "      <td>31.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-11-30</td>\n",
              "      <td>Boston</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Frank</td>\n",
              "      <td>None</td>\n",
              "      <td>71000.40</td>\n",
              "      <td>40.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2017-08-25</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>68000.60</td>\n",
              "      <td>27.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-02-14</td>\n",
              "      <td>Seattle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Grace</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2019-09-08</td>\n",
              "      <td>Austin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Henry</td>\n",
              "      <td>Sales</td>\n",
              "      <td>59000.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Ivy</td>\n",
              "      <td>HR</td>\n",
              "      <td>63000.30</td>\n",
              "      <td>36.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Portland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td></td>\n",
              "      <td>Engineering</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Jack</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1000000.99</td>\n",
              "      <td>99.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>Miami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Karen</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>45000.00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2023-06-15</td>\n",
              "      <td>Atlanta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>Leo</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>95000.00</td>\n",
              "      <td>45.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2016-04-18</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Mona</td>\n",
              "      <td>None</td>\n",
              "      <td>52000.50</td>\n",
              "      <td>26.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2022-08-09</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `toPandas()` vs `pandas_api()`\n",
        "---\n",
        "#### Core Architecture\n",
        "| Aspect | `toPandas()` | `pandas_api()` |\n",
        "|--------|-------------|----------------|\n",
        "| **Data Location** | Local memory | Distributed cluster |\n",
        "| **Processing** | Single machine | Distributed parallel |\n",
        "| **Data Movement** | All data moves | No data movement |\n",
        "---\n",
        "#### Performance & Scale\n",
        "| Aspect | `toPandas()` | `pandas_api()` |\n",
        "|--------|-------------|----------------|\n",
        "| **Max Data Size** | RAM limited | Terabytes+ |\n",
        "| **Scalability** | Single machine | Cluster scaling |\n",
        "| **Memory Usage** | High on driver | Distributed |\n",
        "---\n",
        "#### Use Cases\n",
        "| Scenario | `toPandas()` | `pandas_api()` |\n",
        "|----------|-------------|----------------|\n",
        "| **Visualization** | ‚úÖ Ideal | ‚ùå Limited |\n",
        "| **Python ML libs** | ‚úÖ Full support | ‚ùå No support |\n",
        "| **Big data processing** | ‚ùå Cannot handle | ‚úÖ Perfect |\n",
        "| **Production pipelines** | ‚ùå Avoid | ‚úÖ Recommended |\n",
        "| **Prototyping** | ‚úÖ Excellent | ‚úÖ Good |\n",
        "---\n",
        "#### Key Trade-offs\n",
        "---\n",
        "### `toPandas()`\n",
        "- ‚úÖ Full pandas compatibility\n",
        "- ‚úÖ Works with all Python libs\n",
        "- ‚ùå Memory bound\n",
        "- ‚ùå Single machine limit\n",
        "---\n",
        "#### `pandas_api()`\n",
        "- ‚úÖ Handles massive data\n",
        "- ‚úÖ Distributed processing\n",
        "- ‚ùå Partial pandas compatibility\n",
        "- ‚ùå Limited third-party support\n",
        "\n",
        "#### Decision Guide\n",
        "- **Data fits in RAM** ‚Üí `toPandas()`\n",
        "- **Need Python ecosystem** ‚Üí `toPandas()`\n",
        "- **Big data processing** ‚Üí `pandas_api()`\n",
        "- **Production systems** ‚Üí `pandas_api()`\n",
        "\n",
        "**Choose based on data size and required ecosystem integration**"
      ],
      "metadata": {
        "id": "qv3ZPM-T6Wyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toJSON : majorly used for like straming cases\n",
        "\n",
        "print(type(dataframe.toJSON()))\n",
        "print('\\n')\n",
        "dataframe.toJSON().first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "TGXzaK_N1jbZ",
        "outputId": "bc86b4b5-284f-4308-85f8-fc8733906468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.rdd.RDD'>\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"employee_id\":1,\"name\":\"Alice\",\"department\":\"Engineering\",\"salary\":75000.5,\"age\":28,\"is_active\":true,\"hire_date\":\"2020-01-15\",\"city\":\"New York\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toLocalIterator\n",
        "\n",
        "# same pandas.DataFrame.iterrows()\n",
        "\n",
        "dataframeIterator = dataframe.toLocalIterator()\n",
        "\n",
        "for rw in dataframeIterator:\n",
        "  print(rw)\n",
        "  print(rw.name)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G612Chsx7NnM",
        "outputId": "6b74c2ab-8617-4280-9719-019dbde9f0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(employee_id=1, name='Alice', department='Engineering', salary=75000.5, age=28, is_active=True, hire_date=datetime.date(2020, 1, 15), city='New York')\n",
            "Alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inputFile\n",
        "\n",
        "# NOW this dataframe is not created from a source file, the output is empty\n",
        "\n",
        "dataframe.inputFiles()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wpI7K5E-Vic",
        "outputId": "4fe19902-a90f-47a9-883e-93a5b29939ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ApproximateQuantile\n",
        "\n",
        "dataframe.stat.approxQuantile(\"salary\", [0.25, 0.5, 0.75], 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXffAadyCymU",
        "outputId": "1a170040-9078-47f9-a664-2dec60809c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[58000.0, 63000.3, 75000.5]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform\n",
        "\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "def upperCasing(dataframe,col_name):\n",
        "  return dataframe.withColumn(col_name, expr(f'upper({col_name})'))\n",
        "\n",
        "dataframe.transform(upperCasing, 'department').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rnGW-C6D9Ti",
        "outputId": "de5f0275-6418-408b-d7db-371087fc34b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|   name| department|    salary| age|is_active| hire_date|         city|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|          1|  Alice|ENGINEERING|   75000.5|  28|     true|2020-01-15|     New York|\n",
            "|          2|    Bob|  MARKETING|  65000.75|  32|    false|2019-03-20|San Francisco|\n",
            "|          3|Charlie|ENGINEERING|  82000.25|  35|     true|2018-07-10|     New York|\n",
            "|          4|  Diana|      SALES|   58000.0|  29|     true|2021-05-05|      Chicago|\n",
            "|          5|    Eve|         HR|   62000.8|  31|    false|2020-11-30|       Boston|\n",
            "|          6|  Frank|       NULL|   71000.4|  40|     true|2017-08-25|         NULL|\n",
            "|          7|   NULL|ENGINEERING|   68000.6|  27|    false|2022-02-14|      Seattle|\n",
            "|          8|  Grace|  MARKETING|      NULL|  33|     true|2019-09-08|       Austin|\n",
            "|          9|  Henry|      SALES|   59000.9|NULL|    false|2021-12-01|       Denver|\n",
            "|         10|    Ivy|         HR|   63000.3|  36|     NULL|      NULL|     Portland|\n",
            "|         11|       |ENGINEERING|       0.0|   0|    false|2023-01-01|             |\n",
            "|         12|   Jack|      SALES|1000000.99|  99|     true|2015-12-31|        Miami|\n",
            "|         13|  Karen|  MARKETING|   45000.0|  22|     true|2023-06-15|      Atlanta|\n",
            "|         14|    Leo|ENGINEERING|   95000.0|  45|    false|2016-04-18|     New York|\n",
            "|         15|   Mona|       NULL|   52000.5|  26|     true|2022-08-09|      Chicago|\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# createOrReplaceGlobalTempView\n",
        "\n",
        "dataframe.createOrReplaceGlobalTempView('dataframe_globalTempView')\n",
        "\n",
        "sql = '''\n",
        "select *\n",
        "from global_temp.dataframe_globalTempView'''\n",
        "\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f65cR7HjJMjq",
        "outputId": "b2226582-49e0-400a-dbef-1799dcd8d085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# createOrReplaceTempView\n",
        "\n",
        "dataframe.createOrReplaceTempView('dataframe_TempView')\n",
        "\n",
        "sql = '''\n",
        "select *\n",
        "from dataframe_TempView'''\n",
        "\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "id": "1fkOpKuQJROS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32dbce2-59e3-400d-e925-e40f5157baac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|employee_id|name   |department |salary    |age |is_active|hire_date |city         |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "|1          |Alice  |Engineering|75000.5   |28  |true     |2020-01-15|New York     |\n",
            "|2          |Bob    |Marketing  |65000.75  |32  |false    |2019-03-20|San Francisco|\n",
            "|3          |Charlie|Engineering|82000.25  |35  |true     |2018-07-10|New York     |\n",
            "|4          |Diana  |Sales      |58000.0   |29  |true     |2021-05-05|Chicago      |\n",
            "|5          |Eve    |HR         |62000.8   |31  |false    |2020-11-30|Boston       |\n",
            "|6          |Frank  |NULL       |71000.4   |40  |true     |2017-08-25|NULL         |\n",
            "|7          |NULL   |Engineering|68000.6   |27  |false    |2022-02-14|Seattle      |\n",
            "|8          |Grace  |Marketing  |NULL      |33  |true     |2019-09-08|Austin       |\n",
            "|9          |Henry  |Sales      |59000.9   |NULL|false    |2021-12-01|Denver       |\n",
            "|10         |Ivy    |HR         |63000.3   |36  |NULL     |NULL      |Portland     |\n",
            "|11         |       |Engineering|0.0       |0   |false    |2023-01-01|             |\n",
            "|12         |Jack   |Sales      |1000000.99|99  |true     |2015-12-31|Miami        |\n",
            "|13         |Karen  |Marketing  |45000.0   |22  |true     |2023-06-15|Atlanta      |\n",
            "|14         |Leo    |Engineering|95000.0   |45  |false    |2016-04-18|New York     |\n",
            "|15         |Mona   |NULL       |52000.5   |26  |true     |2022-08-09|Chicago      |\n",
            "+-----------+-------+-----------+----------+----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GlobalTempView vs TempView\n",
        "---\n",
        "#### Scope & Visibility\n",
        "| Aspect | **TempView** | **GlobalTempView** |\n",
        "|--------|-------------|-------------------|\n",
        "| **Scope** | Current session only | All sessions |\n",
        "| **SQL Reference** | `view_name` | `global_temp.view_name` |\n",
        "\n",
        "---\n",
        "#### Creation & Lifetime\n",
        "| Aspect | **TempView** | **GlobalTempView** |\n",
        "|--------|-------------|-------------------|\n",
        "| **Creation Method** | `createOrReplaceTempView()` | `createOrReplaceGlobalTempView()` |\n",
        "| **Lifetime** | Session duration | Application duration |\n",
        "---\n",
        "#### Use Cases\n",
        "| Scenario | **TempView** | **GlobalTempView** |\n",
        "|----------|-------------|-------------------|\n",
        "| **Single-session work** | ‚úÖ Ideal | ‚ùå Overkill |\n",
        "| **Cross-session sharing** | ‚ùå Cannot | ‚úÖ Perfect |\n",
        "| **Pipeline steps** | ‚úÖ Good | ‚úÖ Good for results |\n",
        "---\n",
        "#### Key Difference\n",
        "**TempView**: Session-private, no prefix needed  \n",
        "**GlobalTempView**: Cluster-shared, requires `global_temp.` prefix\n",
        "---\n",
        "#### When to Choose\n",
        "- **Isolated work** ‚Üí TempView\n",
        "- **Shared data** ‚Üí GlobalTempView"
      ],
      "metadata": {
        "id": "kon7rbzbMS80"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epNdqPt3LSdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}