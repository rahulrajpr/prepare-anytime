{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBnNJb41biK0cmFT2WeV9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrajpr/prepare-anytime/blob/main/spark/functions/3_spark_sql_date_time_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Date Time Functions\n",
        "https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#date-and-timestamp-functions"
      ],
      "metadata": {
        "id": "AoclFtNV51vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('spark-function').getOrCreate()"
      ],
      "metadata": {
        "id": "FJifnEEm65CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8NTPsjg5vyO",
        "outputId": "a3499383-1648-4ecc-bc8c-be48e4db7058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|currentDate|\n",
            "+-----------+\n",
            "|2025-10-25 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# current_date :\n",
        "sql = '''select current_date() as currentDate'''\n",
        "spark.sql(sql).show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# curdate :\n",
        "sql = '''select curdate() as currentDate'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSyQyNO7aYO",
        "outputId": "2d2fbdf7-1d2f-49ca-b628-d236642ca058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|currentDate|\n",
            "+-----------+\n",
            "|2025-10-25 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# current_timestamp :\n",
        "\n",
        "sql = '''select current_timestamp() as currentTimeStamp'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3vfM4A0HQ0T",
        "outputId": "62222a01-6fe5-4536-ab02-12005ce7e76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|currentTimeStamp          |\n",
            "+--------------------------+\n",
            "|2025-10-25 09:30:46.962398|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# current_timezone :\n",
        "\n",
        "sql = '''select current_timezone() as currentTimeZone'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZQXksr0Hb35",
        "outputId": "aa211ed5-047c-49d0-bb41-187ba79e7d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|currentTimeZone|\n",
            "+---------------+\n",
            "|Etc/UTC        |\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now\n",
        "\n",
        "sql = '''select now() as nowOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pN3xU5wtFBj",
        "outputId": "fc6102d2-c5dc-433e-f36c-ce75135689d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|nowOut                    |\n",
            "+--------------------------+\n",
            "|2025-10-25 09:30:47.550239|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert_timezone\n",
        "\n",
        "sql = '''select convert_timezone('UTC','IST', current_timestamp()) as ISTTime'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "id": "Yf1JGLVwH_gK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf19964a-cd47-486c-ced5-74d170ecd4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|ISTTime                   |\n",
            "+--------------------------+\n",
            "|2025-10-25 12:36:54.231104|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# localtimestamp : the timestamp where the region of the cluster is located\n",
        "\n",
        "sql = '''select localtimestamp() as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "id": "bKWFNPaxfwLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# date_add : adding n numebr of days to an exating date\n",
        "# synonym : dateadd\n",
        "\n",
        "sql = '''select date_add(current_date(),2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_add(current_date(),-2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "##--\n",
        "\n",
        "sql = '''select dateadd(current_date(),2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select dateadd(current_date(),-2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PHV0p_zMMoL",
        "outputId": "0597e314-54a0-41e0-be7a-332b3432422d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-27 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-23 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-27 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-23 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date_sub : substrituting n numebr of days to an exating date\n",
        "# synonym : dateadd\n",
        "\n",
        "sql = '''select date_sub(current_date(),2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_sub(current_date(),-2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg4uqtemaM5X",
        "outputId": "8f667329-9be4-4f94-a6f9-79eb0fa247d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-23 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-27 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add_months : adding n numebr of days to an exating date\n",
        "\n",
        "sql = '''select add_months(current_date(),2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select add_months(current_date(),-2) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toFxAHjAMxcJ",
        "outputId": "36abadac-3cd1-4ce9-bac9-4d52d83d6295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-12-25 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-08-25 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interval : shifting dates using intervals, this keyword is a champion\n",
        "\n",
        "sql = '''select current_date() + interval 2 days as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select current_date() - interval 2 days as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select current_date() + interval 2 months as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select current_date() - interval 2 months as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select current_date() + interval 2 year as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFVgwQlkNLBO",
        "outputId": "7fa56141-3a46-4da2-9ec1-a8f0e27b55fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-27 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-10-23 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-12-25 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2025-08-25 |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|2027-10-25 |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date_diff\n",
        "## this returns the number of days between two different days\n",
        "# synonym : datediff\n",
        "\n",
        "sql = '''select date_diff(current_date()+interval 3 days ,current_date()) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "#---\n",
        "\n",
        "sql = '''select datediff(current_date()+interval 3 days ,current_date()) as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmqzCttANtYN",
        "outputId": "2fa8b9ab-53f4-416b-ca64-73033125bd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|3          |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|date_addOut|\n",
            "+-----------+\n",
            "|3          |\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date diffrence using '-' operator\n",
        "# this return an interval\n",
        "\n",
        "sql = '''select (current_date()+interval 3 days) - current_date() as date_addOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2rg2vhSOHSt",
        "outputId": "d85422f4-4175-49a6-9901-6d7a3c5264f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|date_addOut     |\n",
            "+----------------+\n",
            "|INTERVAL '3' DAY|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract : to return a part from a date or timestamp datatype or interval values\n",
        "\n",
        "sql = '''select extract(days from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(day from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(month from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(quarter from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(year from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(hour from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(minute from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract(second from current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select extract( days from (current_date()+interval 3 days) - current_date()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEKhhVpUOzvl",
        "outputId": "6fe57fdd-86bb-4466-e4c9-7beaf245950c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|25            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|25            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|10            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|4             |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|2025          |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|7             |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|54            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|25.434428     |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|3             |\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date_part : part of a date , similar to extract\n",
        "# the part argument has to be put into '' marks, NOT like extract\n",
        "\n",
        "\n",
        "sql = '''select date_part('day',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_part('month',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_part('year',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_part('hour',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_part('minute',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_part('second',current_timestamp()) as extractedValue'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc3f9v0_WSpm",
        "outputId": "7fa97d24-993f-4a69-80e8-83bb4c2b6884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|25            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|10            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|2025          |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|7             |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|54            |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|extractedValue|\n",
            "+--------------+\n",
            "|8.474983      |\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do_date : to convert as date string to date type\n",
        "\n",
        "sql = '''select to_date('2025-10-25') as to_dateOut, typeOf(to_date('2025-10-25')) as outType'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select to_date('2025-10-25 10:12:10') as to_dateOut, typeOf(to_date('2025-10-25 10:12:10')) as outType'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmM8PCxaPKgc",
        "outputId": "583b2a19-133a-44ee-f5cf-d5bb413dfd2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "|to_dateOut|outType|\n",
            "+----------+-------+\n",
            "|2025-10-25|date   |\n",
            "+----------+-------+\n",
            "\n",
            "+----------+-------+\n",
            "|to_dateOut|outType|\n",
            "+----------+-------+\n",
            "|2025-10-25|date   |\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_timestamp : to convert as date string to timestamp type\n",
        "\n",
        "sql = '''select to_timestamp('2025-10-25') as to_dateOut, typeOf(to_timestamp('2025-10-25')) as outType'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select to_timestamp('2025-10-25 10:12:10') as to_dateOut, typeOf(to_timestamp('2025-10-25 10:12:10')) as outType'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umH79ItaS-Bs",
        "outputId": "e740136c-3307-4542-f570-bab9183cd93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+---------+\n",
            "|to_dateOut         |outType  |\n",
            "+-------------------+---------+\n",
            "|2025-10-25 00:00:00|timestamp|\n",
            "+-------------------+---------+\n",
            "\n",
            "+-------------------+---------+\n",
            "|to_dateOut         |outType  |\n",
            "+-------------------+---------+\n",
            "|2025-10-25 10:12:10|timestamp|\n",
            "+-------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date_format\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'dd-MMM-yyyy') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'dd-MMMM-yyyy') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'E') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'EEEE') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'EEEE, dd-MMMM-yyyy') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'dd-MMMM-yyyy HH:mm') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "sql = '''select date_format(current_timestamp(),'dd-MMMM-yyyy HH:mm a') as date_formatOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAmDjGeFTt74",
        "outputId": "d05383da-52e9-4a3a-954d-a3fc69eeda92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|date_formatOut|\n",
            "+--------------+\n",
            "|25-Oct-2025   |\n",
            "+--------------+\n",
            "\n",
            "+---------------+\n",
            "|date_formatOut |\n",
            "+---------------+\n",
            "|25-October-2025|\n",
            "+---------------+\n",
            "\n",
            "+--------------+\n",
            "|date_formatOut|\n",
            "+--------------+\n",
            "|Sat           |\n",
            "+--------------+\n",
            "\n",
            "+--------------+\n",
            "|date_formatOut|\n",
            "+--------------+\n",
            "|Saturday      |\n",
            "+--------------+\n",
            "\n",
            "+-------------------------+\n",
            "|date_formatOut           |\n",
            "+-------------------------+\n",
            "|Saturday, 25-October-2025|\n",
            "+-------------------------+\n",
            "\n",
            "+---------------------+\n",
            "|date_formatOut       |\n",
            "+---------------------+\n",
            "|25-October-2025 07:49|\n",
            "+---------------------+\n",
            "\n",
            "+------------------------+\n",
            "|date_formatOut          |\n",
            "+------------------------+\n",
            "|25-October-2025 07:49 AM|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# date_trunc\n",
        "\n",
        "sql = '''select date_trunc('day',current_timestamp()) as date_truncOut'''\n",
        "spark.sql(sql).show(truncate = True)\n",
        "\n",
        "sql = '''select date_trunc('month',current_timestamp()) as date_truncOut'''\n",
        "spark.sql(sql).show(truncate = True)\n",
        "\n",
        "sql = '''select date_trunc('quarter',current_timestamp()) as date_truncOut'''\n",
        "spark.sql(sql).show(truncate = True)\n",
        "\n",
        "sql = '''select date_trunc('year',current_timestamp()) as date_truncOut'''\n",
        "spark.sql(sql).show(truncate = True)\n",
        "\n",
        "sql = '''select date_trunc('hour',current_timestamp()) as date_truncOut'''\n",
        "spark.sql(sql).show(truncate = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6KvUW2nT-8a",
        "outputId": "a4b84506-a57b-4633-f34d-4a91b7737d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|      date_truncOut|\n",
            "+-------------------+\n",
            "|2025-10-25 00:00:00|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|      date_truncOut|\n",
            "+-------------------+\n",
            "|2025-10-01 00:00:00|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|      date_truncOut|\n",
            "+-------------------+\n",
            "|2025-10-01 00:00:00|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|      date_truncOut|\n",
            "+-------------------+\n",
            "|2025-01-01 00:00:00|\n",
            "+-------------------+\n",
            "\n",
            "+-------------------+\n",
            "|      date_truncOut|\n",
            "+-------------------+\n",
            "|2025-10-25 08:00:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# day :\n",
        "\n",
        "sql = '''select day(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wumBn-jya3KR",
        "outputId": "86208c3e-a8ec-4046-f39f-1ebd3e2b5c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|25      |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# month\n",
        "\n",
        "sql = '''select month(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmwwHNnQcKMl",
        "outputId": "f07c0404-8291-4a1d-8acc-3b23c55edca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|10      |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# year\n",
        "\n",
        "sql = '''select year(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdSa5y1dcREN",
        "outputId": "99b0b096-60a0-4970-d65a-7d88513be8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|2025    |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hour\n",
        "\n",
        "sql = '''select hour(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODXVLgPrcUsU",
        "outputId": "c5b9599d-cc9c-44bf-b8e2-b95a69c7238a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|8       |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# minute\n",
        "\n",
        "sql = '''select minute(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COcXyeIqcY_8",
        "outputId": "5dfa2e2b-82aa-4678-f867-f4ddad86e1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|23      |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second\n",
        "\n",
        "sql = '''select second(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uivyFx9KcewW",
        "outputId": "6a6e0917-2876-4944-b2d9-afda7ff8aee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|16      |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dayofmonth\n",
        "\n",
        "sql = '''select dayofmonth(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_JuwGbUcj2s",
        "outputId": "f5faf41f-600d-40e6-83be-5fdb8f08e82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|25      |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dayofweek\n",
        "# Sun - 1, Sat - 7\n",
        "\n",
        "sql = '''select dayofweek(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7rLDMTHdWvf",
        "outputId": "a37b6fed-d94f-4997-de27-26798fd65178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|7       |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dayofyear\n",
        "\n",
        "sql = '''select dayofyear(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmaz2C3sdcPx",
        "outputId": "2a2995e7-53dc-4bcd-d448-669e633e82fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|date_out|\n",
            "+--------+\n",
            "|298     |\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last_day : last day of the month\n",
        "\n",
        "sql = '''select last_day(current_timestamp()) as date_out'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad6TBGnpd1Ki",
        "outputId": "0cb756d5-d112-4659-f027-7e7cd458af96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|date_out  |\n",
            "+----------+\n",
            "|2025-10-31|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_date : create a date from date parts\n",
        "\n",
        "sql = '''select make_date(2025,10,25) as make_dateOut'''\n",
        "spark.sql(sql).show(truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOAYvGKafl1t",
        "outputId": "5ae3c901-15d0-44b1-e60b-0b1f689a675b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|make_dateOut|\n",
            "+------------+\n",
            "|2025-10-25  |\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_dt_interval : create date interval\n",
        "\n",
        "sql = '''select make_dt_interval(1,10,25,0) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "## same thing can be achieved using the interval keyword\n",
        "\n",
        "sql = '''select interval 1 day 10 hours 25 minutes 0 seconds as intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2L8X9K2gXAK",
        "outputId": "af6202c8-ffd2-48ab-f02a-19fff0713bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+\n",
            "|make_intervalOut                   |\n",
            "+-----------------------------------+\n",
            "|INTERVAL '1 10:25:00' DAY TO SECOND|\n",
            "+-----------------------------------+\n",
            "\n",
            "+-----------------------------------+\n",
            "|intervalOut                        |\n",
            "+-----------------------------------+\n",
            "|INTERVAL '1 10:25:00' DAY TO SECOND|\n",
            "+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_ym_interval : create date interval\n",
        "\n",
        "sql = '''select make_ym_interval(1,10) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "## same thing can be achieved using the interval keyword\n",
        "\n",
        "sql = '''select interval 1 year + 10 months as intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLGlVoyJmkYB",
        "outputId": "a2548021-2e04-43b0-8a61-10ba9a2603f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|make_intervalOut             |\n",
            "+-----------------------------+\n",
            "|INTERVAL '1-10' YEAR TO MONTH|\n",
            "+-----------------------------+\n",
            "\n",
            "+-----------------------------+\n",
            "|intervalOut                  |\n",
            "+-----------------------------+\n",
            "|INTERVAL '1-10' YEAR TO MONTH|\n",
            "+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_interval : create a make interval\n",
        "\n",
        "sql = '''select make_interval(1,2,4,10,25,0) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "## same thing canNOT be achieved using the interval keyword\n",
        "## because spark does not allow to add the yeat-month and date interval directly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAUA8BlIgm9N",
        "outputId": "c71a8b71-b580-4a34-e59a-9a642452e384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+\n",
            "|make_intervalOut                 |\n",
            "+---------------------------------+\n",
            "|1 years 2 months 38 days 25 hours|\n",
            "+---------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_timestamp\n",
        "\n",
        "sql = '''select make_timestamp(2025,10,25,10,25,0) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNODlyMZg08m",
        "outputId": "b6d9aeff-a3f7-4286-bfb0-4fda055401c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|make_intervalOut   |\n",
            "+-------------------+\n",
            "|2025-10-25 10:25:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_timestamp_ltz : make time stamp with local time zone\n",
        "\n",
        "sql = '''select make_timestamp_ltz(2025,10,25,10,25,0, 'UTC') as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGS3rT05jQE8",
        "outputId": "808257ed-14ba-4b05-87fb-d6ecaa8de1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|make_intervalOut   |\n",
            "+-------------------+\n",
            "|2025-10-25 10:25:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make_timestamp_ntz : make time stamp with no time zone\n",
        "\n",
        "sql = '''select make_timestamp_ntz(2025,10,25,10,25,0) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChQNganzmQCX",
        "outputId": "31e64e60-0585-44d8-c2da-de2fd46c904c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|make_intervalOut   |\n",
            "+-------------------+\n",
            "|2025-10-25 10:25:00|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# months_between\n",
        "\n",
        "sql = '''select months_between(current_timestamp()+interval 10 months , current_timestamp()) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)\n",
        "\n",
        "##-- using extract\n",
        "\n",
        "sql = '''select ((current_timestamp()+interval 10 months) - current_timestamp()) as make_intervalOut'''\n",
        "spark.sql(sql).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKBWa-h2mZ7O",
        "outputId": "87801c2b-7f6e-49c6-bf5f-517de9309faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|make_intervalOut|\n",
            "+----------------+\n",
            "|10.0            |\n",
            "+----------------+\n",
            "\n",
            "+-------------------------------------+\n",
            "|make_intervalOut                     |\n",
            "+-------------------------------------+\n",
            "|INTERVAL '304 00:00:00' DAY TO SECOND|\n",
            "+-------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Note: Date and Time Intervals in Spark\n",
        "\n",
        "## Understanding Interval Families\n",
        "\n",
        "Spark distinguishes between two main types of intervals:\n",
        "\n",
        "1. **YEAR-MONTH Interval**\n",
        "   - Handles: months and years\n",
        "   - Use when working with calendar-based periods\n",
        "\n",
        "2. **DAY-TIME Interval**\n",
        "   - Handles: days, hours, minutes, and seconds\n",
        "   - Use when working with specific durations\n",
        "\n",
        "## Important Limitation\n",
        "\n",
        "**You cannot directly cast a day interval to a month interval** because the length of a month is variable (28â€“31 days).\n",
        "\n",
        "- For conversions, a common approximation is: **1 month = 30 days**\n",
        "- Conversion between these interval types is done through division\n",
        "\n",
        "---\n",
        "\n",
        "## Key Interval Functions\n",
        "\n",
        "### 1. `make_interval()`\n",
        "**Purpose:** Creates a DAY-TIME interval with flexibility across multiple time units\n",
        "\n",
        "**Unique Importance:** Most versatile function - allows you to specify years, months, weeks, days, hours, minutes, and seconds all in one call\n",
        "\n",
        "**Use when:** You need to create intervals that span multiple units or need the most flexible option\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `make_dt_interval()`\n",
        "**Purpose:** Creates a DAY-TIME interval specifically for day and sub-day units\n",
        "\n",
        "**Unique Importance:** Focused on precise time durations without calendar complexity (days, hours, minutes, seconds)\n",
        "\n",
        "**Use when:** Working with exact time durations that don't involve month/year calculations\n",
        "\n",
        "---\n",
        "\n",
        "### 3. `make_ym_interval()`\n",
        "**Purpose:** Creates a YEAR-MONTH interval specifically for calendar-based periods\n",
        "\n",
        "**Unique Importance:** Designed for calendar arithmetic - handles years and months correctly accounting for variable month lengths\n",
        "\n",
        "**Use when:** Working with calendar-based periods where month and year precision matters (e.g., age calculations, subscription periods)\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Reference Summary\n",
        "\n",
        "| Function | Interval Type | Best For |\n",
        "|----------|--------------|----------|\n",
        "| `make_interval()` | Mixed (most flexible) | Complex intervals spanning multiple units |\n",
        "| `make_dt_interval()` | DAY-TIME | Precise time durations |\n",
        "| `make_ym_interval()` | YEAR-MONTH | Calendar-based periods |"
      ],
      "metadata": {
        "id": "c3vTfCvmp1G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# next_day : to get the day for next day name\n",
        "\n",
        "sql = '''select next_day(current_date(),'Monday') as nextMonday'''\n",
        "spark.sql(sql).show(truncate = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btaAJfk2nE9g",
        "outputId": "d6499046-7115-4ce4-e13e-ffd3c418d8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|nextMonday|\n",
            "+----------+\n",
            "|2025-10-27|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQOgbjShs0TK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}